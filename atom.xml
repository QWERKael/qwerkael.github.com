<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[阿勒西的小屋]]></title>
  <link href="http://qwerkael.cn/atom.xml" rel="self"/>
  <link href="http://qwerkael.cn/"/>
  <updated>2020-07-21T17:04:30+08:00</updated>
  <id>http://qwerkael.cn/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im/">MWeb</generator>
  
  <entry>
    <title type="html"><![CDATA[在Go中调用Rust动态库]]></title>
    <link href="http://qwerkael.cn/15959947592394.html"/>
    <updated>2020-07-29T11:52:39+08:00</updated>
    <id>http://qwerkael.cn/15959947592394.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">使用cbindgen生成Rust代码的C绑定</h2>

<p>编辑<code>Cargo.toml</code>文件</p>

<pre><code class="language-toml">[lib]
name = &quot;speaker&quot;
path = &quot;src/plugins/speaker.rs&quot;
crate-type = [&quot;cdylib&quot;]

[build-dependencies]
cbindgen = &quot;*&quot;
</code></pre>

<p>在<code>build.rs</code>中调用<code>cbindgen</code>生成头文件</p>

<pre><code class="language-rust">extern crate cbindgen;

fn main() {
    let crate_dir = std::env::var(&quot;CARGO_MANIFEST_DIR&quot;).unwrap();

    cbindgen::Builder::new()
        .with_language(cbindgen::Language::C)
        .with_crate(crate_dir)
        .generate()
        .expect(&quot;Unable to generate C bindings.&quot;)
        .write_to_file(&quot;src/plugins/speaker.h&quot;);
}
</code></pre>

<p>因为<code>cbindgen</code>默认会生成<code>C++</code>的头文件, 但是<code>cgo</code>只支持<code>C</code>库而不支持<code>C++</code>库, 所以我们需要用<code>with_language(cbindgen::Language::C)</code>的方式指定生成<code>C</code>的头文件<br/>
现在我们用<code>Rust</code>写一个简单的动态库</p>

<pre><code class="language-rust">#[no_mangle]
pub extern &quot;C&quot; fn run() {
    println!(&quot;Hello, speaker!&quot;);
}
</code></pre>

<p>执行<code>cargo build</code>命令, 会生成头文件<code>speaker.h</code>和动态库文件<code>libspeaker.dylib</code></p>

<h2 id="toc_1">使用cgo运行动态库</h2>

<pre><code class="language-go">package main

/*
#cgo CFLAGS: -I./include
#cgo LDFLAGS: -L./lib -lspeaker

#include &lt;speaker.h&gt;
*/
import &quot;C&quot;

func main() {
    C.run()
}
</code></pre>

<p>首先在代码中添加<code>import &quot;C&quot;</code>表示使用<code>cgo</code>特性<br/>
在<code>import &quot;C&quot;</code>之前的注释中使用<code>#cgo</code>来设置编译和链接阶段的相关参数<br/>
<code>CFLAGS</code>表示用于<code>C</code>编译器的选项, 使用<code>-I</code>指定头文件所在的目录<br/>
<code>LDFLAGS</code>告诉链接器从哪里找寻库文件(在<code>unix</code>系统中, <code>ld</code>常作为<code>load</code>或者<code>loader</code>的缩写使用), 使用<code>-L</code>指定库所在的目录, 使用<code>-l</code>指定库名</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[在Rust中调用Rust动态库]]></title>
    <link href="http://qwerkael.cn/15955630261644.html"/>
    <updated>2020-07-24T11:57:06+08:00</updated>
    <id>http://qwerkael.cn/15955630261644.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">配置Cargo.toml</h2>

<p>首先我们先在<code>Cargo.toml</code>中添加相关配置</p>

<pre><code class="language-rust">[[bin]]
name = &quot;master&quot;
path = &quot;src/master/master.rs&quot;

[lib]
name = &quot;speaker&quot;
path = &quot;src/plugins/speaker.rs&quot;
crate-type = [&quot;cdylib&quot;]

[dependencies]
libloading = &quot;*&quot;
</code></pre>

<p>其中, <code>speaker</code>是动态库, <code>master</code>是调用动态库的主程序</p>

<h2 id="toc_1">创建动态库</h2>

<pre><code class="language-rust">#[no_mangle]
pub extern fn run() {
    println!(&quot;Hello, speaker!&quot;);
}
</code></pre>

<p><code>#[no_mangle]</code>表示禁用<code>name mangling</code>, 它表示以原始的函数名编译函数, 因为在一些支持重载的语言中, 编译的函数名并不是在代码中声明的函数名, 而是函数名加参数类型.</p>

<h2 id="toc_2">在主程序中调用动态库</h2>

<pre><code class="language-rust">extern crate libloading as lib;

fn call_dynamic() -&gt; Result&lt;u32, Box&lt;dyn std::error::Error&gt;&gt; {
    let lib = lib::Library::new(&quot;/Data/Rust/learn4libloading/target/debug/libspeaker.dylib&quot;)?;
    unsafe {
        let func: lib::Symbol&lt;unsafe extern fn() -&gt; u32&gt; = lib.get(b&quot;run&quot;)?;
        Ok(func())
    }
}

fn main() {
    println!(&quot;Hello, master!&quot;);
    let rst = call_dynamic();
    match rst {
        Ok(i) =&gt; println!(&quot;{}&quot;, i),
        Err(e) =&gt; println!(&quot;{}&quot;, e)
    }

}
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[<编译原理>读书笔记]]></title>
    <link href="http://qwerkael.cn/15953908368697.html"/>
    <updated>2020-07-22T12:07:16+08:00</updated>
    <id>http://qwerkael.cn/15953908368697.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">第一章 引论</h2>

<h3 id="toc_1">1.1　语言处理器</h3>

<ol>
<li>编译器(compiler)就是将一种语言编写的程序翻译成另一种语言编写的程序
<img src="media/15953908368697/15953971601586.jpg" alt=""/>
目标程序可以被调用并产生输出
<img src="media/15953908368697/15953973411000.jpg" alt=""/></li>
<li><p>解释器(interpreter)直接利用源程序将输入映射成为输出. <br/>
<img src="media/15953908368697/15953975695267.jpg" alt=""/></p>
<blockquote>
<p>对比编译器和解释器: 编译器生成的目标程序比解释器快, 解释器的错误诊断效果比编译器好</p>
</blockquote></li>
<li><p>混合编译器. 如JAVA, JAVA源程序先被编译为字节码(bytecode), 而后由虚拟机对字节码进行解释<br/>
 <img src="media/15953908368697/15953978574478.jpg" alt=""/></p>
<blockquote>
<p>字节码的优点: 字节码有更好的跨平台的通用性<br/>
JIT编译器: 有些被称为即时 （just in time）编译器的Java编译器在运行中间程序处理输入的前一刻首先把字节码翻译成为机器语言，然后再执行程序</p>
</blockquote></li>
</ol>

<p><strong><em>一个语言处理系统的流程</em></strong><br/>
<img src="media/15953908368697/15954005261816.jpg" alt=""/></p>

<p>预处理器(preprocessor)负责两项工作:</p>

<ol>
<li>将分割成多个模块的源程序聚合起来</li>
<li>将宏转化为源语言语句</li>
</ol>

<h3 id="toc_2">1.2　一个编译器的结构</h3>

<p><strong><em>一个编译器的各个步骤</em></strong><br/>
<img src="media/15953908368697/15954068200383.jpg" alt=""/></p>

<h4 id="toc_3">1.2.1　词法分析</h4>

<blockquote>
<p>词法分析(exical analysis)是编译器的第一个步骤, 又被称为扫描(scanning).<br/>
通过词法分析器将字符流转化成为有意义的词素(lexeme)的序列.<br/>
而词素会被表示为形如<code>&lt;token-name, attribute-value&gt;</code>的词法单元(token)</p>
</blockquote>

<p>源程序<br/>
position = initial + rate * 60<br/>
经过词法分析后被表示为<br/>
<id. 1> &lt;=&gt; <id, 2> &lt;+&gt; <id, 3> &lt;*&gt; <60></p>

<p><strong><em>一个赋值语句的翻译</em></strong><br/>
<img src="media/15953908368697/15954091199027.jpg" alt=""/></p>

<h4 id="toc_4">1.2.2　语法分析</h4>

<blockquote>
<p>语法分析(syntax analysis)是编译器的第二个步骤, 又被称为解析(parsing).<br/>
语法分析器使用由词法分析器生成的各个词法单元的第一个分量来创建树形的中间表示</p>
</blockquote>

<h4 id="toc_5">1.2.3　语义分析</h4>

<blockquote>
<p>语义分析器(semantic analyzer)使用<code>语法树</code>和<code>符号表</code>中的信息来检查源程序是否和语言定义的语义一致。它同时也收集类型信息，并把这些信息存放在语法树或符号表中，以便在随后的中间代码生成过程中使用。</p>
</blockquote>

<p>语义分析阶段的工作内容有:</p>

<ol>
<li>类型检查(type checking): 编译器检查每个运算符是否具有匹配的运算分量。比如，数组下表必须是整数类型。</li>
<li>自动类型转换(coercion)</li>
</ol>

<h4 id="toc_6">1.2.4　中间代码生成</h4>

<p>中间表示在源程序翻译成目标代码的过程中, 可能有一个或多个<br/>
中间表示有多种形式, 如:语法树和三地址代码(three-address code), 其中语法树常用在语法分析和语义分析中<br/>
三地址代码,例如<br/>
<img src="media/15953908368697/15954754764667.jpg" alt=""/><br/>
有三个特点</p>

<ol>
<li>每个三地址赋值指令的右部最多只有一个运算符</li>
<li>编译器应该生成一个临时名字以存放一个三地址指令计算得到的值</li>
<li>有些三地址指令的运算分量的少于三个（比如上面的序列1.3中的第一个和最后一个指令）</li>
</ol>

<h4 id="toc_7">1.2.5　代码优化</h4>

<p>机器无关的代码优化通过改进中间代码使代码更快或者更短/能耗更低</p>

<h4 id="toc_8">1.2.6　代码生成</h4>

<p>将中间表示形式映射为目标语言<br/>
合理分配寄存器以存放变量的值</p>

<h4 id="toc_9">1.2.7　符号表管理</h4>

<p>记录源程序中使用的变量的名字，并收集和每个名字的各种属性有关的信息</p>

<h4 id="toc_10">1.2.8　将多个步骤组合成趟</h4>

<p>在一个特定的实现中，多个步骤的活动可以被组合成一趟 （pass）<br/>
<img src="media/15953908368697/15954832966282.jpg" alt=""/><br/>
前端可以和不同的后端组合</p>

<h4 id="toc_11">1.2.9　编译器构造工具</h4>

<p>一些常用的编译器构造工具包括：</p>

<ol>
<li>语法分析器的生成器： 可以根据一个程序设计语言的语法描述自动生成语法分析器。</li>
<li>扫描器的生成器： 可以根据一个语言的语法单元的正则表达式描述生成词法分析器。</li>
<li>语法制导的翻译引擎： 可以生成一组用于遍历分析树并生成中间代码的例程。</li>
<li>代码生成器的生成器： 依据一组关于如何把中间语言的每个运算翻译成为目标机上的机器语言的规则，生成一个代码生成器。</li>
<li>数据流分析引擎： 可以帮助收集数据流信息，即程序中的值如何从程序的一个部分传递到另一部分。数据流分析是代码优化的一个重要部分。</li>
<li>编译器构造工具集： 提供了可用于构造编译器的不同阶段的例程的完整集合。</li>
</ol>

<h3 id="toc_12">1.3　程序设计语言的发展历程</h3>

<h4 id="toc_13">1.3.1　走向高级程序设计语言</h4>

<p>语言的分类:<br/>
根据代分类</p>

<ol>
<li>第一代语言 是机器语言，</li>
<li>第二代语言 是汇编语言，</li>
<li>第三代语言 是Fortran、Cobol、Lisp、C、C++、C#及Java这样的高级程序设计语言。</li>
<li>第四代语言 是为特定应用设计的语言，比如用于生成报告的NOMAD，用于数据库查询的SQL和用于文本排版的Postscript。</li>
<li>第五代语言 指的是基于逻辑和约束的语言，比如Prolog和OPS5。</li>
</ol>

<p>强制式 （imperative）语言<br/>
声明式 （declarative）语言<br/>
冯·诺伊曼语言 （von Neumann language）<br/>
面向对象语言 （object-oriented language）<br/>
脚本语言 （scripting language）</p>

<h4 id="toc_14">1.3.2　对编译器的影响</h4>

<h3 id="toc_15">1.4　构建一个编译器的相关科学</h3>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[在Rust中调用Go动态库]]></title>
    <link href="http://qwerkael.cn/15952377845247.html"/>
    <updated>2020-07-20T17:36:24+08:00</updated>
    <id>http://qwerkael.cn/15952377845247.html</id>
    <content type="html"><![CDATA[
<p>最近在研究Rust和Go语言如何相互调用, 这样可以发挥两个语言各自的优势, 用Go语言能够进行快速的开发, 用Rust语言可以提升程序的性能和安全性</p>

<h2 id="toc_0">编译Go动态库</h2>

<pre><code class="language-go">package main

import &quot;C&quot;
import &quot;fmt&quot;

//export Hello
func Hello(str string) {
    fmt.Printf(&quot;Hello: %s!\n&quot;, str)
    fmt.Printf(&quot;Hello: %#v!\n&quot;, str)
}

func main() {}
</code></pre>

<p>在编写Go动态库时需要</p>

<ol>
<li>引入<code>C</code>库</li>
<li>保留一个空的<code>main</code>函数</li>
<li>在函数的上一行需要用<code>//export 函数名</code>的形式指定需要导出的函数名</li>
</ol>

<p>我们使用<code>go build</code>命令编译上面的源码</p>

<pre><code class="language-shell">go build -buildmode=c-shared -o /Data/Rust/learn4libloading/src/plugins/libhello.so hello.go
</code></pre>

<p>我直接编译到Rust代码的目录中了<br/>
这样, 我们在编译的目录中会多出两个文件<code>libhello.so</code>文件和<code>libhello.h</code>文件<br/>
<code>libhello.so</code>就是动态库了, 而<code>libhello.h</code>是<code>C</code>的头文件<br/>
我们可以看一下<code>libhello.h</code>的内容</p>

<pre><code class="language-c">/* Code generated by cmd/cgo; DO NOT EDIT. */

/* package command-line-arguments */


#line 1 &quot;cgo-builtin-export-prolog&quot;

#include &lt;stddef.h&gt; /* for ptrdiff_t below */

#ifndef GO_CGO_EXPORT_PROLOGUE_H
#define GO_CGO_EXPORT_PROLOGUE_H

#ifndef GO_CGO_GOSTRING_TYPEDEF
typedef struct { const char *p; ptrdiff_t n; } _GoString_;
#endif

#endif

/* Start of preamble from import &quot;C&quot; comments.  */




/* End of preamble from import &quot;C&quot; comments.  */


/* Start of boilerplate cgo prologue.  */
#line 1 &quot;cgo-gcc-export-header-prolog&quot;

#ifndef GO_CGO_PROLOGUE_H
#define GO_CGO_PROLOGUE_H

typedef signed char GoInt8;
typedef unsigned char GoUint8;
typedef short GoInt16;
typedef unsigned short GoUint16;
typedef int GoInt32;
typedef unsigned int GoUint32;
typedef long long GoInt64;
typedef unsigned long long GoUint64;
typedef GoInt64 GoInt;
typedef GoUint64 GoUint;
typedef __SIZE_TYPE__ GoUintptr;
typedef float GoFloat32;
typedef double GoFloat64;
typedef float _Complex GoComplex64;
typedef double _Complex GoComplex128;

/*
  static assertion to make sure the file is being used on architecture
  at least with matching size of GoInt.
*/
typedef char _check_for_64_bit_pointer_matching_GoInt[sizeof(void*)==64/8 ? 1:-1];

#ifndef GO_CGO_GOSTRING_TYPEDEF
typedef _GoString_ GoString;
#endif
typedef void *GoMap;
typedef void *GoChan;
typedef struct { void *t; void *v; } GoInterface;
typedef struct { void *data; GoInt len; GoInt cap; } GoSlice;

#endif

/* End of boilerplate cgo prologue.  */

#ifdef __cplusplus
extern &quot;C&quot; {
#endif


extern void Hello(GoString p0);

#ifdef __cplusplus
}
#endif
</code></pre>

<p>这其中对我们来说最重要的内容就是<code>Go</code>中的类型在<code>C</code>中是如何定义的, 只有知道这些信息, 我们才能在<code>Rust</code>中调用相应的类型构建<code>Go</code>动态库中需要用到的类型</p>

<h2 id="toc_1">使用Rust调用Go动态库</h2>

<p>在<code>Rust</code>代码中我用到了一个<code>crate</code>叫做<code>libloading</code></p>

<pre><code class="language-rust">extern crate libloading as lib;
use std::ffi::CString;

#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct GoString {
    pub p: *const ::std::os::raw::c_char,
    pub n: isize,
}

fn callGolang(go_name: GoString) -&gt; Result&lt;u32, Box&lt;dyn std::error::Error&gt;&gt; {
    let lib = lib::Library::new(&quot;/Data/Rust/learn4libloading/src/plugins/libhello.so&quot;)?;
    unsafe {
        let func: lib::Symbol&lt;unsafe extern fn(GoString)&gt; = lib.get(b&quot;Hello&quot;)?;
        func(go_name);
        Ok(0)
    }
}

fn main() {
    let c_name = CString::new(&quot;Alex&quot;).unwrap();

    let go_str_ref = GoString {
        p: c_name.as_ptr(),
        n: c_name.as_bytes().len() as isize,
    };

    let _ = callGolang(go_str_ref);
}
</code></pre>

<p>其中的关键是, 先定义了一个<code>GoString</code>结构体, 对应<code>Go</code>语言中的<code>string</code>类型.<br/>
然后用<code>libloading</code>加载动态库, 获取我们需要的函数, 再将对应的<code>GoString</code>类型参数传递过去.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[<超越感觉：批判性思考指南>读书笔记]]></title>
    <link href="http://qwerkael.cn/15934181114037.html"/>
    <updated>2020-06-29T16:08:31+08:00</updated>
    <id>http://qwerkael.cn/15934181114037.html</id>
    <content type="html"><![CDATA[
<p>P.S.: 原文的摘录在笔记中会用 <strong><em>斜体加粗</em></strong> 表示</p>

<ul>
<li>
<a href="#toc_0">导论</a>
</li>
<li>
<a href="#toc_1">第一篇 背景</a>
<ul>
<li>
<a href="#toc_2">第一章 你是谁?</a>
<ul>
<li>
<a href="#toc_3">时间和地点的影响</a>
</li>
<li>
<a href="#toc_4">大众文化的影响</a>
</li>
<li>
<a href="#toc_5">操纵的“学问”</a>
</li>
<li>
<a href="#toc_6">心理学的影响</a>
</li>
<li>
<a href="#toc_7">成为个体</a>
</li>
</ul>
</li>
<li>
<a href="#toc_8">第二章　什么是批判性思考？</a>
<ul>
<li>
<a href="#toc_9">心智、大脑，抑或两者兼有？</a>
</li>
<li>
<a href="#toc_10">批判性思考的定义</a>
</li>
<li>
<a href="#toc_11">批判性思考者的特点</a>
</li>
<li>
<a href="#toc_12">直觉的作用</a>
</li>
<li>
<a href="#toc_13">批判性思考的基本活动</a>
</li>
<li>
<a href="#toc_14">批判性思考与写作</a>
</li>
<li>
<a href="#toc_15">批判性思考与讨论</a>
</li>
<li>
<a href="#toc_16">避免抄袭</a>
</li>
</ul>
</li>
<li>
<a href="#toc_17">第三章　真理是什么？</a>
<ul>
<li>
<a href="#toc_18">究竟始于何处？</a>
</li>
<li>
<a href="#toc_19">不完善的感知</a>
</li>
<li>
<a href="#toc_20">不完善的记忆</a>
</li>
<li>
<a href="#toc_21">有缺陷的信息</a>
</li>
<li>
<a href="#toc_22">即使最明智的人也会出错</a>
</li>
<li>
<a href="#toc_23">真理是发现的，不是创造的</a>
</li>
<li>
<a href="#toc_24">总结</a>
</li>
</ul>
</li>
<li>
<a href="#toc_25">第四章　认知意味着什么？</a>
<ul>
<li>
<a href="#toc_26">认知的必要条件</a>
</li>
<li>
<a href="#toc_27">检验你自己的知识</a>
</li>
<li>
<a href="#toc_28">我们如何知道</a>
</li>
<li>
<a href="#toc_29">为什么认知是困难的</a>
</li>
<li>
<a href="#toc_30">一个警示故事</a>
</li>
<li>
<a href="#toc_31">信仰是一种形式的知识吗？</a>
</li>
<li>
<a href="#toc_32">知识的障碍</a>
</li>
</ul>
</li>
<li>
<a href="#toc_33">第五章　你的观点有多少根据？</a>
</li>
</ul>
</li>
</ul>


<h2 id="toc_0">导论</h2>

<p>导论介绍了本书的写作目的: 为读者 <strong><em>介绍批判性思考</em></strong></p>

<p>并且将本书的内容划分为3个部分:</p>

<ol>
<li>背景: 帮你正确理解一些概念</li>
<li>易犯的错误: 识别并避免常见的谬误</li>
<li>策略: 教你解决问题的技巧</li>
</ol>

<h2 id="toc_1">第一篇 背景</h2>

<p>本篇会讨论7个重要的概念: </p>

<ol>
<li>个性</li>
<li>批判性思考</li>
<li>真理</li>
<li>知识</li>
<li>观点</li>
<li>证据</li>
<li>论证</li>
</ol>

<h3 id="toc_2">第一章 你是谁?</h3>

<p>这一章是对&quot;个性&quot;概念的探讨<br/>
我们对自己的认知不仅包含客观的身高体重年龄, 也包括主观的情感和喜好.<br/>
而我们之所以能成为现在的我们, 不仅仅是&quot;<strong><em>由于我自己的选择</em></strong>&quot;.<br/>
事实上, &quot;<strong><em>世界对我们的影响远远超出了我们大多数人的认识</em></strong>&quot;</p>

<h4 id="toc_3">时间和地点的影响</h4>

<p>时代背景和生活的环境会塑造一个人<br/>
<strong><em>生活在不同的时代或文化背景下，会使你成为一个不同的人。即使你叛逆你所处的时间和空间的价值观，它们仍然会代表你生活的环境——换句话说，它们依然会影响你作出的反应。</em></strong></p>

<h4 id="toc_4">大众文化的影响</h4>

<p>大众文化: 广播媒体、报纸、杂志和流行音乐<br/>
特点: 影响力巨大, 且隐蔽<br/>
比如, 现代广告通过诉诸情感, 改造了我们的价值观: <strong><em>广告经常描绘消遣比工作更让人满足，自满比自制更令人渴望，物质主义比理想主义更有意义。</em></strong><br/>
比如, 电视节目, 通过不断地打断和转移我们的注意力, 并持续不断的为我们创造新的刺激来俘获观众, 同时也造成了我们无法长时间集中注意力.<br/>
比如, 越来越多的需要思考的书籍被消遣之作代替, 严谨的回答被简单的判断代替, 公正的报道被轰动的爆点代替, 政客们更关注的不是政策而是营销.<br/>
总之, 大众文化总是通过迎合我们的欲望来放大我们的缺点, 而这种影响不是突然地, 而是潜移默化的.</p>

<h4 id="toc_5">操纵的“学问”</h4>

<p>人们不仅会被操纵, 而且很容易被操纵, 人们之所以这么容易被操纵, 恰恰是因为人们相信&quot;<strong><em>自己不会被操纵</em></strong>&quot;<br/>
对于人而言, 不仅情感会被操作, 甚至记忆也会被操纵</p>

<h4 id="toc_6">心理学的影响</h4>

<p>心理学不仅在观察这我们的思想, 心理学也在改变着我们的思想<br/>
心理学家们从我们的思想中总结出规律并提出假设, 而一旦我们被其假说所说服, 我们的思想也会受到其支配</p>

<h4 id="toc_7">成为个体</h4>

<p>我们的个性不是与生俱来的, 而是后天不断地演化而来的.<br/>
而在演化的过程中, 不可避免的会受到他人和环境的影响.<br/>
在个性的演化过程中我们应该保持一个谨慎的态度, 并且遵循以下一些原则, 来保证我们能够成为一个真正的个体, 而不是被各种别有用心的信息操纵的人:</p>

<ol>
<li>你对任何信息的第一反应都应当是尝试性的, 而不是毫无保留的接受</li>
<li>思考你为何会作出此种反应</li>
<li>思考你还可以作出其他那些反应</li>
<li>判断是否有其他反应比第一反应恰当</li>
</ol>

<h3 id="toc_8">第二章　什么是批判性思考？</h3>

<p>什么是&quot;思考&quot;?<br/>
我们在日常生活中常常提及它, 却又很难给它下一个准确的定义<br/>
它包含的意涵广泛, &quot;<strong><em>从白日梦到反思和分析</em></strong>&quot;都可以被称为&quot;思考&quot;<br/>
人们总是被要求&quot;思考&quot;, 但是, 对于大多数人而言&quot;<strong><em>广泛、有效的思维训练是例外而非常规</em></strong>&quot;<br/>
<strong><em>我们大多数所谓的推理在于为继续相信我们已经相信的东西找到理由</em></strong></p>

<h4 id="toc_9">心智、大脑，抑或两者兼有？</h4>

<p>心智(mind)和大脑(brain)两者是否相同?<br/>
大脑(brain)是物质的, 而心智(mind)则是形而上的<br/>
<strong><em>大脑是思考的必要条件，但没有表明大脑是思考的充分条件</em></strong><br/>
心智是消极的还是积极的?<br/>
消极: 约翰·洛克（John Locke）认为心智是&quot;<strong><em>经验书写于其上的“白板”</em></strong>&quot;<br/>
积极: 莱布尼茨（G. W. Leibnitz）认为心智是&quot;<strong><em>我们用以采取主动并行使我们自由意志的工具</em></strong>&quot;</p>

<h4 id="toc_10">批判性思考的定义</h4>

<p>思考和感觉的区分<br/>
感觉是应激的主观反应<br/>
感觉不能代替思考, <strong><em>因为它极不可靠</em></strong><br/>
<strong><em>思考则是用以解决问题、作出决定或取得理解而进行的有意识的精神过程</em></strong><br/>
<strong><em>感觉和思考之间的关系，感觉需要检验才能信赖，而思考就是检验感觉最合理和最可靠的方法</em></strong><br/>
<strong><em>思考有两大类：创造性的和批判性的</em></strong><br/>
<strong><em>批判性思考的本质是评价</em></strong><br/>
<strong><em>批判性思考中所使用的最重要的技巧之一是提问探索性的问题</em></strong><br/>
<strong><em>非批判的思考者会接受他们自己最初的想法和他人陈述的表面价值，而批判的思考者则质疑所有的想法</em></strong><br/>
<strong><em>批判性思考也通过提出问题来分析议题</em></strong></p>

<blockquote>
<p>总结一下, 本段主要讲了两个划分<br/>
其一, 是思考和感觉的划分, 他们的主要区分点是&quot;有意识&quot;还是&quot;无意识&quot;<br/>
感觉是无意识的(应激的)主观反应<br/>
思考是有意识的探索过程<br/>
其二, 是创造性思考和批判性思考的划分, 文中只讲了批判性思考, 而我又查了一些资料, 对创造性思考进行了自己的理解<br/>
我认为二者的主要区分点在于思考的对象<br/>
创造性思考是对未知的思考, 它可以是对未知事物的思考, 也可以是对已知事务的未知方面的思考<br/>
而批判性思考则是对已知的思考, 是对已知事务批判性的评价, 是对已知事务合理性的验证<br/>
到这里, 我们可以试着去定义一下什么是思考了,<br/>
在我看来, 思考就是对客观事物合理化的过程<br/>
既然有&quot;合理化&quot;, 那我们就应该先定义什么是&quot;合理&quot;, &quot;合理&quot;就像是数学中的公理一样, 不证自明. 我们会根据我们自身的经验为理解世界设定一些&quot;公理&quot;, 这是我们理解世界的基础, 但这并不意味着我们的这些理念就是正确的.<br/>
这其实就像是&quot;拟合&quot;<br/>
创造性思维就是用我们的&quot;公理&quot;去解释未知的事物<br/>
而批判性思维就是, 我们如何评价别人的解释</p>
</blockquote>

<h4 id="toc_11">批判性思考者的特点</h4>

<p>对于批判性思维的四个误解</p>

<ol>
<li><strong><em>认为，能够通过推理来支持自己的信念，就可成为批判性思考者</em></strong>
还要看推理是否合理和充分</li>
<li><strong><em>批判性思考者从不模仿他人的思想和行动</em></strong>
重要的是合理而不是独特</li>
<li><strong><em>批判性思考是一个人头脑中拥有许多正确答案的同义语</em></strong>
思维主要是寻找答案的过程, 而且很难评判什么是&quot;正确答案&quot;</li>
<li><strong><em>批判性思考不能通过学习来获得，人们要么“有”、要么没有批判性思考</em></strong>
<strong><em>批判性思考是一个习惯问题</em></strong>, 是可以后天培养的</li>
</ol>

<p>批判性思考者的两个特征</p>

<ol>
<li><strong><em>提出恰当问题的技巧</em></strong></li>
<li><strong><em>学会如何控制自己的思想，积极和消极地运用心智</em></strong></li>
</ol>

<p>批判性思考者往往有这样一些特点<br/>
有清晰的自我认知, 不回避问题和争议, 并保持好奇心和耐心, 理性客观, 愿意倾听, 不极端, 克制情感</p>

<h4 id="toc_12">直觉的作用</h4>

<p>直觉是我们对事物的直观感受<br/>
有时直觉可以帮助我们处理问题, 但是它有着一些局限性:</p>

<ol>
<li>即是直觉能够帮助我们处理一些问题, 但是这也是建立在我们平时的良好的思维训练的基础上</li>
<li>直觉有可能出错</li>
<li>由于幸存者偏差, 我们很难对直觉作出客观评价</li>
</ol>

<p>有些学者认为, 所谓的直觉, 只是我们没有意识到我们进行了思考</p>

<h4 id="toc_13">批判性思考的基本活动</h4>

<p>思考的顺序应该是<br/>
调查(收集证据) -&gt; 解释(整理证据) -&gt; 判断(得出结论)<br/>
在这个过程中, 我们可以先假设然后再论证<br/>
但是不能用预设立场去干扰推理</p>

<h4 id="toc_14">批判性思考与写作</h4>

<p>写作有两个作用:</p>

<ol>
<li>发现思想</li>
<li>交流思想</li>
</ol>

<p>对于&quot;发现思想&quot;而言, 写作可以帮助我们记录思维的过程, 由此可以更好的发散思维并验证</p>

<h4 id="toc_15">批判性思考与讨论</h4>

<p>讨论一定会带来矛盾, 这种矛盾一方面会促进我们解决问题和决策, 另一方面也会带来情绪上的对立<br/>
为了促成前者而避免后者, 我们应当遵循一些原则</p>

<ol>
<li><strong><em>只要可能，就提前做准备</em></strong></li>
<li><strong><em>设定合理的预期</em></strong>: 不要期望自己一定能说服对手</li>
<li><strong><em>抛弃自我中心和个人议程</em></strong>: 尊重别人的观点</li>
<li><strong><em>起作用但不主导一切</em></strong>: 适度的发表自己的观点, 不要过于滔滔不绝, 要不要过于沉默</li>
<li><strong><em>避免分散注意力的讲话习惯</em></strong>: 你的表达要<strong><em>清晰明了、直截了当和经济有效</em></strong></li>
<li><strong><em>积极的倾听</em></strong>: 倾听, 并保持注意力</li>
<li><strong><em>负责任地判断思想</em></strong>: 审慎的思考, 而不是简单地感觉</li>
<li><strong><em>抵制喊叫或打断的冲动</em></strong></li>
</ol>

<h4 id="toc_16">避免抄袭</h4>

<p>避免不经意间的抄袭</p>

<ol>
<li><strong><em>当你研究一个课题时，把其他来源的思想与你自己的思想区分开来</em></strong>
查阅资料时, 把每条信息的来源都记录下来</li>
<li><strong><em>当你阅读每个资料来源时，用笔记记下你想在自己的写作中引用的思想</em></strong>
可以用圆括号标注引用的信息源, 用方括号标注自己对引述的评价</li>
<li><strong><em>你在写论文时，通过审慎地运用引语和改述来把借用的思想和语言加入你自己的作品中。</em></strong></li>
</ol>

<h3 id="toc_17">第三章　真理是什么？</h3>

<p>过去人们常常谈论 <strong><em>绝对真理</em></strong> <br/>
有人相信它存在, 认为它是一种精神实在, 这些人中有人认为它可以被认知, 另一些则认为它不能被认知<br/>
而另外一些人则干脆认为它不存在, 认为它只是一个空洞的观念<br/>
现在人们所谈论的所谓&quot;真理&quot;更相对和主观, 也不注重检验其合理性</p>

<h4 id="toc_18">究竟始于何处？</h4>

<p>在孩提时代, 我们对世界的理解往往依赖于外界的灌输(比如, 父母), 虽然成年以后我们能够依赖自己的判断去认知世界, 但是童年时被灌输的观点依然后影响我们一生</p>

<h4 id="toc_19">不完善的感知</h4>

<p>感知的缺点:</p>

<ol>
<li>会受主观情绪的影响, 感知是有选择的, 有局限性的</li>
<li>经常出错</li>
</ol>

<h4 id="toc_20">不完善的记忆</h4>

<p><strong><em>即使我们的感知最初是正确无误的，我们的记忆也经常扭曲它。</em></strong><br/>
尤其是细节.<br/>
我们会用自认为合理的行为代替真实发生的事情.</p>

<h4 id="toc_21">有缺陷的信息</h4>

<p>我们坚信一件事情为真理, 很大程度上取决于我们接受到的信息.<br/>
而我们所接受到的信息很可能会误导我们, 即是你是该领域的专家.</p>

<h4 id="toc_22">即使最明智的人也会出错</h4>

<p>群体判断或许会好些, 但也会出错</p>

<h4 id="toc_23">真理是发现的，不是创造的</h4>

<p>我们可以创造信念, 但是无法创造真理<br/>
<strong><em>我知道我有局限性并且容易出错。而且，毫无疑问，我将永远不可能找到自己想知道的所有答案。但是，我可以观察得更准确一点，权衡问题更全面一点，作出决定时更仔细一点。如果我这么做了，我就会更接近真理。</em></strong></p>

<h4 id="toc_24">总结</h4>

<blockquote>
<p>真理分为两种, &quot;绝对真理&quot;和&quot;相对整理&quot;<br/>
历史上人们有很多关于&quot;绝对真理&quot;的观点, 但是从未找到过一个能够被描述出来的&quot;绝对真理&quot;<br/>
&quot;相对真理&quot;会更主观一点, 但是&quot;相对真理&quot;会更受限于我们的感知/记忆和依凭的信息以及作出的判断, 从而&quot;并不总是正确&quot;<br/>
我们往往只能更逼近真理, 而不是达到真理</p>
</blockquote>

<h3 id="toc_25">第四章　认知意味着什么？</h3>

<p>我们坚信的并不一定是正确的</p>

<h4 id="toc_26">认知的必要条件</h4>

<p><strong><em>知道不仅包括正确答案。它还包括认识到你已经拥有了它。</em></strong><br/>
<strong><em>认知通常也意味着其他事情——有能力表达知道什么和我们如何得知它</em></strong><br/>
不仅知道, 还要能确信你知道的即是正确<br/>
不仅知其然, 还要知其所以然</p>

<h4 id="toc_27">检验你自己的知识</h4>

<p>我们所认为的&quot;真理&quot;可能并不是正确的<br/>
<strong><em>摆脱自负。因为任何人都不可能开始学习他认为自己早已知道的事。</em></strong></p>

<h4 id="toc_28">我们如何知道</h4>

<p>主动的获得知识: </p>

<ol>
<li>检验和证实</li>
<li>推理和分析</li>
</ol>

<p>被动的获得知识:</p>

<ol>
<li>学习</li>
<li>交流</li>
</ol>

<p>被动的获得知识的缺点: 知识可能在传播的过程中被扭曲</p>

<h4 id="toc_29">为什么认知是困难的</h4>

<p>认知困难的原因:</p>

<ol>
<li>老问题没解决</li>
<li>新问题又出现了</li>
<li>已经解决的问题被忽视或否认, 又变成了未解决的问题</li>
</ol>

<h4 id="toc_30">一个警示故事</h4>

<p>这是一个关于<code>塔萨代部落（Tasaday tribe）</code>真伪性的故事</p>

<h4 id="toc_31">信仰是一种形式的知识吗？</h4>

<p><strong><em>宗教信仰这一术语表示对不能证明的某事的信仰</em></strong><br/>
<strong><em>这并不是说相信的事情不真实，而只是说它的真实性不能被确定性地证明</em></strong></p>

<h4 id="toc_32">知识的障碍</h4>

<p><strong><em>设定就是把某事看作理所当然的</em></strong><br/>
<strong><em>未予确证的设定的主要负面影响是其扼杀了通向知识的好奇心。</em></strong></p>

<p><strong><em>猜想是提出一个直觉判断或是冒险提出一个对正确性没有任何信心的答案</em></strong></p>

<p><strong><em>因为设定扼杀了好奇心，而猜想拒绝了证据的重要性，所以它们任何一个都不可能通往知识</em></strong></p>

<p>通往知识最可靠的方法:</p>

<ol>
<li>谨慎的断言</li>
<li>坦承自己的无知</li>
</ol>

<h3 id="toc_33">第五章　你的观点有多少根据？</h3>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[< MySQL Innternals Manual >阅读笔记]]></title>
    <link href="http://qwerkael.cn/15934177615172.html"/>
    <updated>2020-06-29T16:02:41+08:00</updated>
    <id>http://qwerkael.cn/15934177615172.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">Chapter 1 A Guided Tour Of The MySQL Source Code</a>
<ul>
<li>
<a href="#toc_1">1.1 Getting the Source Tree</a>
</li>
<li>
<a href="#toc_2">1.2 The Major Directories</a>
<ul>
<li>
<a href="#toc_3">1.2.1 Major Directories: BUILD</a>
<ul>
<li>
<a href="#toc_4">1.2.1.1 GNU Debugger</a>
</li>
<li>
<a href="#toc_5">1.2.1.2 Running a Test with the Debugger</a>
</li>
</ul>
</li>
</ul>
</li>
<li>
<a href="#toc_6">1.2.2 Major Directories: client</a>
</li>
<li>
<a href="#toc_7">1.2.3 Major Directories: myisam</a>
</li>
</ul>
</li>
</ul>


<h2 id="toc_0">Chapter 1 A Guided Tour Of The MySQL Source Code</h2>

<p>这一章主要是讲MySQL源码的各个目录和其作用</p>

<h3 id="toc_1">1.1 Getting the Source Tree</h3>

<ol>
<li><p>从GitHub克隆MySQL源码</p>
<pre><code class="language-shell">me@mymachine:~$ git clone https://github.com/mysql/mysql-server.git 
# 在国内可以使用镜像, 速度会快一点<br/>
git clone https://github.com.cnpmjs.org/mysql/mysql-server.git
</code></pre></li>
<li><p>在mysql-server的目录中可以查看源码的目录结构</p>
<pre><code class="language-shell">me@mymachine:~$ cd mysql-server
me@mymachine:~/mysql-server$ ls<br/>
BUILD            COPYING             libmysqld    regex          tests<br/>
BUILD-CMAKE      dbug                libservices  scripts        unittest<br/>
client           Docs                man          sql            VERSION<br/>
cmake            extra               mysql-test   sql-bench      vio<br/>
CMakeLists.txt   include             mysys        sql-common     win<br/>
cmd-line-utils   INSTALL-SOURCE      packaging    storage        zlib<br/>
config.h.cmake   INSTALL-WIN-SOURCE  plugin       strings<br/>
configure.cmake  libmysql            README       support-files
</code></pre></li>
<li><p>使用<code>git branch -r</code>查看“remote-tracking”分支</p>
<pre><code class="language-shell">~/mysql-server$ git branch -r
origin/5.5<br/>
origin/5.6<br/>
origin/5.7<br/>
origin/HEAD -&gt; origin/5.7
</code></pre></li>
<li><p>使用<code>git branch</code>查看当前分支</p>
<pre><code class="language-shell">~/mysql-server$ git branch
* 5.7
</code></pre></li>
<li><p>使用<code>git checkout</code>迁出指定分支</p>
<pre><code class="language-shell">~/mysql-server$ git checkout 5.6
Branch 5.6 set up to track remote branch 5.6 from origin.<br/>
Switched to a new branch &#39;5.6&#39;<br/>
me@mymachine:~/mysql-server$ git checkout 5.5<br/>
Branch 5.5 set up to track remote branch 5.5 from origin.<br/>
Switched to a new branch &#39;5.5&#39;
</code></pre></li>
<li><p>再次使用<code>git branch</code>查看当前的所有分支, 可以看到, 一共有3个分支, 5.5是当前分支</p>
<pre><code class="language-shell">~/mysql-server$ git branch
* 5.5<br/>
5.6<br/>
5.7
</code></pre></li>
</ol>

<h3 id="toc_2">1.2 The Major Directories</h3>

<p>这一章介绍7个主要的目录</p>

<h4 id="toc_3">1.2.1 Major Directories: BUILD</h4>

<p><code>BUILD</code>目录负责编译和连接</p>

<pre><code class="language-shell">shell&gt; ./BUILD/compile-pentium-debug --prefix=$HOME/mysql-bin
</code></pre>

<blockquote>
<p><code>compile-pentium-debug</code>其实就是一个简单的shell脚本, 在8.0里面已经没有BUILD文件夹了</p>

<pre><code class="language-shell"># compile-pentium-debug 脚本
path=`dirname $0`
cmake $path/.. -DWITH_DEBUG=1
make
</code></pre>
</blockquote>

<p>这个命令会调用一个批处理文件生成MySQL的服务端和客户端的可执行程序<br/>
如果缺少相应的依赖包, 会执行失败<br/>
编译完后, 使用以下命令安装</p>

<pre><code class="language-shell">shell&gt; make
shell&gt; make install
shell&gt; $HOME/mysql-bin/scripts/mysql_install_db \
 --basedir=$HOME/mysql-bin \
 --datadir=$HOME/mysql-bin/var
</code></pre>

<h5 id="toc_4">1.2.1.1 GNU Debugger</h5>

<p>推荐通过<a href="http://www.gnu.org/software/gdb/documentation/">gdb(GNU debugger)</a>调试运行中的程序<br/>
也可以使用图形化的调试工具<a href="http://www.gnu.org/software/ddd/manual/">DDD(Data Display Debugger)</a><br/>
使用以下命令调试mysqld服务</p>

<pre><code class="language-shell">shell&gt; ddd --gdb --args \
     $HOME/mysql-bin/libexec/mysqld \
     --basedir=$HOME/mysql-bin \
     --datadir=$HOME/mysql-bin/var\
     --skip-networking
</code></pre>

<h5 id="toc_5">1.2.1.2 Running a Test with the Debugger</h5>

<p>通过<code>嵌入模式(embedded mode)</code>运行一个名为<code>some.test</code>的测试:</p>

<ol>
<li>运行<code>libmysqld/examples/test_run --gdb some.test</code>命令来创建一个<code>libmysqld/examples/test-gdbinit</code>文件, 这个文件包含了<code>mysqltest</code>所需的参数</li>
<li>因为在<code>test-run --gdb</code>命令执行完成之后, <code>test-gdbinit</code>文件就会被移除, 所以我们要在那之前将<code>test-gdbtest</code>文件先拷贝一个备份(比如叫做<code>some-gdbtest</code>)</li>
<li>选一个调试器(debugger)加载<code>libmysqld/examples/mysqltest_embedded</code>, 比如<code>gdb mysqltest_embedded</code></li>
<li>在debugger里面执行<code>--sou some-gdbtest</code></li>
</ol>

<p>如果只是想调试嵌入式服务的一些查询, 而不是测试脚本, 那么只需要运行<code>libmysqld/examples/mysql</code>就可以了. 他是mysql常用工具的克隆, 是基于服务器内嵌的. 能在<code>gdb</code>和其他debugger下良好工作.</p>

<h3 id="toc_6">1.2.2 Major Directories: client</h3>

<p>这里面主要都是些客户端程序的源码</p>

<h3 id="toc_7">1.2.3 Major Directories: myisam</h3>

<p>在最新的<code>MySQL8.0</code>里面, <code>MyISAM</code>存储引擎已经不再使用了, <code>MySQL</code>的引擎源码存储在<code>storage</code>目录底下</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[为InnoDB存储引擎配置内存分配器]]></title>
    <link href="http://qwerkael.cn/15934194114231.html"/>
    <updated>2020-06-29T16:30:11+08:00</updated>
    <id>http://qwerkael.cn/15934194114231.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>这是一篇MySQL官方文档的翻译，是我在查阅InnoDB额外内存池相关资料时找到的</p>
</blockquote>

<p><a href="https://dev.mysql.com/doc/refman/5.7/en/innodb-performance-use_sys_malloc.html">原文链接</a></p>

<h2 id="toc_0">14.6.4 Configuring the Memory Allocator for InnoDB</h2>

<blockquote>
<p>14.6.4 为InnoDB存储引擎配置内存分配器</p>
</blockquote>

<p>​When InnoDB was developed, the memory allocators supplied with operating systems and run-time libraries were often lacking in performance and scalability. At that time, there were no memory allocator libraries tuned for multi-core CPUs. Therefore, InnoDB implemented its own memory allocator in the mem subsystem. This allocator is guarded by a single mutex, which may become a bottleneck. InnoDB also implements a wrapper interface around the system allocator (malloc and free) that is likewise guarded by a single mutex.</p>

<blockquote>
<p>在InnoDB存储引擎被开发时，操作系统和运行时库所提供的内存分配器在性能和扩展性上都表现欠佳。当时并没有针对多核CPU调优的内存分配器库。因此，InnoDB在mem子系统中自己实现了一个内存分配器。这个分配器被一个单一的互斥锁保护着，而这则可能会导致瓶颈。InnoDB也实现了一个基于系统分配器（malloc和free）的包装接口，同样的，也被单一互斥锁保护着。</p>
</blockquote>

<p>Today, as multi-core systems have become more widely available, and as operating systems have matured, significant improvements have been made in the memory allocators provided with operating systems. These new memory allocators perform better and are more scalable than they were in the past. Most workloads, especially those where memory is frequently allocated and released (such as multi-table joins), benefit from using a more highly tuned memory allocator as opposed to the internal, InnoDB-specific memory allocator.</p>

<blockquote>
<p>现在，随着多核系统的广泛应用和操作系统的不断成熟，操作系统所提供的内存分配器也取得了重大的进步。新的内存分配器在性能和扩展性方面都比之前的要更加优异。在大多数的工作负载（尤其是需要频繁的分配和释放内存的）场景下，使用经过高度调优的内存分配器要比使用InnoDB特定的内置的内存分配器效果更好。</p>
</blockquote>

<p>​You can control whether InnoDB uses its own memory allocator or an allocator of the operating system, by setting the value of the system configuration parameterinnodb_use_sys_malloc in the MySQL option file (my.cnf or my.ini). If set to ON or 1 (the default), InnoDB uses the malloc and freefunctions of the underlying system rather than manage memory pools itself. This parameter is not dynamic, and takes effect only when the system is started. To continue to use the InnoDB memory allocator, set innodb_use_sys_malloc to 0.</p>

<blockquote>
<p>你可以通过配置MySQL配置文件（my.cnf or my.ini）中的innodb_use_sys_malloc参数来控制InnoDB是使用自带的内存分配器还是使用操作系统提供的内存分配器。如果参数被设置为ON或者1（这也是默认值），InnoDB会使用当前系统下的malloc和free函数，而不是维护一个自己的内存池。这个参数并非是动态的，它会随着系统的启动而生效。将innodb_use_sys_malloc设置为0，则会继续使用InnoDB的内存分配器。</p>
</blockquote>

<p>​When the InnoDB memory allocator is disabled, InnoDB ignores the value of the parameter innodb_additional_mem_pool_size. The InnoDB memory allocator uses an additional memory pool for satisfying allocation requests without having to fall back to the system memory allocator. When the InnoDB memory allocator is disabled, all such allocation requests are fulfilled by the system memory allocator.</p>

<blockquote>
<p>当InnoDB内存分配器被关闭是，InnoDB会忽略innodb_additional_mem_pool_size参数的值。InnoDB内存分配器使用一个额外的内存池来满足分配请求，而不必依赖于系统的内存分配器。而当InnoDB内存分配器不可用时，所有的分配请求都将由系统的内存分配器来满足。</p>
</blockquote>

<p>​On Unix-like systems that use dynamic linking, replacing the memory allocator may be as easy as making the environment variable LD_PRELOAD or LD_LIBRARY_PATH point to the dynamic library that implements the allocator. On other systems, some relinking may be necessary. Please refer to the documentation of the memory allocator library of your choice.</p>

<blockquote>
<p>在使用动态链接的类Unix系统上，替换内存分配器很简单，只要将环境变量LD_PRELOAD or LD_LIBRARY_PATH指向实现了分配器的动态库就行。在其他系统中则需要重新连接。请参考你所选择的内存分配器库的相关文档。</p>
</blockquote>

<p>​Since InnoDB cannot track all memory use when the system memory allocator is used (innodb_use_sys_malloc is ON), the section “BUFFER POOL AND MEMORY” in the output of the SHOW ENGINE INNODB STATUS command only includes the buffer pool statistics in the “Total memory allocated”. Any memory allocated using the mem subsystem or using ut_malloc is excluded.</p>

<blockquote>
<p>当使用系统内存分配器（innodb_use_sys_malloc设为ON）时，InnoDB无法跟踪内存的使用，因此在使用SHOW ENGINE INNODB STATUS命令查看输出中的BUFFER POOL AND MEMORY信息时“Total memory allocated”仅包含了缓冲池（buffer pool）的统计。而没有使用mem子系统或者ut_malloc的内存分配。</p>
</blockquote>

<p>Note</p>

<p>​innodb_use_sys_malloc and innodb_additional_mem_pool_size were deprecated in MySQL 5.6 and removed in MySQL 5.7.</p>

<blockquote>
<p>innodb_use_sys_malloc和innodb_additional_mem_pool_size在MySQL 5.6中被弃用，在MySQL 5.7中被移除。</p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[同步MySQL增量数据到ClickHouse]]></title>
    <link href="http://qwerkael.cn/15934197733993.html"/>
    <updated>2020-06-29T16:36:13+08:00</updated>
    <id>http://qwerkael.cn/15934197733993.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">安装</a>
<ul>
<li>
<a href="#toc_1">kafka</a>
</li>
<li>
<a href="#toc_2">Maxwell</a>
</li>
<li>
<a href="#toc_3">clickhouse</a>
</li>
</ul>
</li>
<li>
<a href="#toc_4">同步数据</a>
<ul>
<li>
<a href="#toc_5">使用Python从kafka导入数据到clickhouse</a>
</li>
</ul>
</li>
</ul>


<h2 id="toc_0">安装</h2>

<h3 id="toc_1">kafka</h3>

<p><code>kafka</code>的安装只需要下载、解压、启动即可</p>

<pre><code class="language-shell">wget http://mirror.its.dal.ca/apache/kafka/1.0.0/kafka_2.11-1.0.0.tgz
tar -zxf kafka_2.11-1.0.0.tgz 
cd kafka_2.11-1.0.0/
</code></pre>

<p><code>kafka</code>需要依赖于<code>zk</code>，<code>zk</code>可以直接使用<code>kafka</code>安装包里自带的<code>zk</code>。</p>

<pre><code class="language-shell">bin/zookeeper-server-start.sh config/zookeeper.properties &amp;
</code></pre>

<p>但是在启动之前，我们可能需要先修改一下配置文件<code>config/server.properties</code><br/>
一般需要修改的几个参数有</p>

<pre><code class="language-shell"># kafka broker的id
broker.id=0
# kafka监听的地址
listeners=PLAINTEXT://:9092
# kafka的日志地址
log.dirs=/tmp/kafka-logs
# kafka使用的zk的地址
zookeeper.connect=localhost:2181
</code></pre>

<p>启动<code>broker</code></p>

<pre><code class="language-shell">bin/kafka-server-start.sh config/server.properties &amp;
</code></pre>

<p>查看<code>kafka</code>是否启动了</p>

<pre><code class="language-shell">$ jps
1240 QuorumPeerMain
1817 Jps
1518 Kafka
</code></pre>

<p>上面的<code>QuorumPeerMain</code>就是<code>zk</code>，<code>Kafka</code>就是我们刚才启动的<code>broker</code><br/>
我们还可以在启动两个新<code>broker</code>，但是需要先复制配置文件并修改里面的<code>broker.id</code>、<code>listeners</code>、<code>log.dirs</code>值，使之不冲突</p>

<pre><code class="language-shell">bin/kafka-server-start.sh config/server-1.properties &amp;
bin/kafka-server-start.sh config/server-2.properties &amp;
</code></pre>

<p>然后我们可以测试一些简单的操作<br/>
创建名为<code>test</code>的<code>topic</code>，只有一个分区，一个副本</p>

<pre><code class="language-shell">bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --partitons 1 --topic test
</code></pre>

<p>查看<code>topic</code></p>

<pre><code class="language-shell">bin/kafka-topics.sh --list --zookeeper 127.0.0.1:2181
</code></pre>

<p>查看<code>test</code>的分区和副本状态</p>

<pre><code class="language-shell">bin/kafka-topics.sh --describe --zookeeper 127.0.0.1:2181 --topic test
</code></pre>

<p>使用生产者推送消息</p>

<pre><code class="language-shell">bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
</code></pre>

<p>然后打开另一个窗口，使用消费者从开始获取消息</p>

<pre><code class="language-shell">bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning
</code></pre>

<h3 id="toc_2">Maxwell</h3>

<p>关于<code>Maxwell</code>的相关资料可以直接查看<a href="http://maxwells-daemon.io/">官网</a><br/>
下载并解压<code>maxwell</code></p>

<pre><code class="language-shell">wget https://github.com/zendesk/maxwell/releases/download/v1.13.2/maxwell-1.13.2.tar.gz
tar -zxf maxwell-1.13.2.tar.gz
cd maxwell-1.13.2
</code></pre>

<p>在<code>mysql</code>中创建一个<code>maxwell</code>账户</p>

<pre><code class="language-sql">GRANT ALL on maxwell.* to &#39;maxwell&#39;@&#39;%&#39; identified by &#39;XXXXXX&#39;;
GRANT SELECT, REPLICATION CLIENT, REPLICATION SLAVE on *.* to &#39;maxwell&#39;@&#39;%&#39;;
</code></pre>

<p>拷贝一份配置文件的模板<code>config.properties.example</code></p>

<pre><code class="language-shell">cp config.properties.example config.properties
</code></pre>

<p>然后编辑配置文件，并将<code>ddl操作</code>发送给单独的<code>topic</code></p>

<pre><code class="language-ini"># tl;dr config
log_level=info
producer=kafka
kafka.bootstrap.servers=localhost:9092

# mysql login info
host=localhost
user=maxwell
password=maxwell

######### output format stuff ###############
# 记录binlog position（默认关闭）
output_binlog_position=true
# 记录gtid（默认关闭）
output_gtid_position=true
# 记录空值字段（默认开启）
output_nulls=true
# 记录server_id（默认关闭）
output_server_id=true
# 记录thread_id（默认关闭）
output_thread_id=true
# 记录原始的SQL语句，需要在mysql中打开参数&quot;binlog_rows_query_log_events&quot; must be enabled&quot;（默认关闭）
output_row_query=true
# 记录commit和xid信息（默认开启）
output_commit_info=true
# 记录ddl操作
output_ddl=true

######### kafka stuff ###############
# binlog日志解析到的topic
kafka_topic=maxwell
# ddl操作的binlog日志解析到的topic，需要开启前面的output_ddl选项
ddl_kafka_topic=maxwell_ddl
</code></pre>

<p>为<code>maxwell</code>创建<code>topic</code></p>

<pre><code class="language-shell">bin/kafka-topics.sh --zookeeper 127.0.0.1:2181 --create --topic maxwell --partitions 20 --replication-factor 1
bin/kafka-topics.sh --zookeeper 127.0.0.1:2181 --create --topic maxwell_ddl --partitions 1 --replication-factor 1
</code></pre>

<p>使用配置文件启动<code>maxwell</code></p>

<pre><code class="language-shell">bin/maxwell --config=config.properties &amp;
</code></pre>

<p>现在我们可以修改数据库的数据，然后在kafka目录下观察队列中的数据</p>

<pre><code class="language-shell"># 在kafka中查看binlog的变化
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic maxwell --from-beginning
# 在kafka中查看ddl的binlog的变化
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic maxwell_ddl --from-beginning
</code></pre>

<h3 id="toc_3">clickhouse</h3>

<p><a href="https://clickhouse.yandex/#quick-start">官方文档</a>直接提供了使用<code>apt-get</code>安装的方法<br/>
但是官方并没有提供<code>yum</code>的安装方法，我这里使用了<a href="https://github.com/red-soft-ru/clickhouse-rpm">第三方</a>提供的仓库，</p>

<pre><code class="language-shell"># 安装yum-config-manager程序
yum install yum-utils
# centos 6 的仓库
yum-config-manager --add-repo http://repo.red-soft.biz/repos/clickhouse/repo/clickhouse-el6.repo
# centos 7 的仓库
yum-config-manager --add-repo http://repo.red-soft.biz/repos/clickhouse/repo/clickhouse-el7.repo
# 安装软件包
yum install clickhouse-server clickhouse-client clickhouse-server-common clickhouse-compressor
</code></pre>

<p>修改配置文件<code>vim /etc/clickhouse-server/config.xml</code></p>

<pre><code class="language-shell">...
&lt;!-- 修改监听IP --&gt;
&lt;listen_host&gt;::&lt;/listen_host&gt;
   &lt;listen_host&gt;0.0.0.0&lt;/listen_host&gt;

...

   &lt;!-- 修改数据路径 --&gt;
   &lt;path&gt;/data/clickhouse/&lt;/path&gt;
   &lt;tmp_path&gt;/data/clickhouse/tmp/&lt;/tmp_path&gt;
...
</code></pre>

<p>启动服务</p>

<pre><code class="language-shell">service clickhouse-server start
</code></pre>

<p>进入<code>clickhouse</code></p>

<pre><code class="language-shell">clickhouse-client -mn
</code></pre>

<p>创建</p>

<pre><code class="language-sql">CREATE TABLE data_record.row_record ( 
    r_date Date,  
    database String,  
    table String,  
    type String,  
    ts Int64,  
    xid Int64,  
    position String,  
    gtid Nullable(String),  
    server_id Int64,  
    thread_id Int64,  
    data String,  
    old String) ENGINE = MergeTree(r_date, (r_date, database, table), 8192)
</code></pre>

<h2 id="toc_4">同步数据</h2>

<h3 id="toc_5">使用Python从kafka导入数据到clickhouse</h3>

<p>下面是一个简单的例子</p>

<pre><code class="language-python"># -*- coding: utf-8 -*-
from confluent_kafka import Consumer, KafkaError
import clickhouse_driver
import logging
import json
import datetime


class ChWriter(object):
    def __init__(self, setting):
        self.conn = clickhouse_driver.Client(**setting)

    def ch_insert(self, sql, dicts):
        &quot;&quot;&quot;插入数据&quot;&quot;&quot;
        self.conn.execute(sql, dicts)


def prefunc(data):
    data[&#39;r_date&#39;] = datetime.datetime.fromtimestamp(data[&#39;ts&#39;]).date()
    print(&#39;timestamp:&#39;, data[&#39;ts&#39;], &#39;\n&#39;, &#39;date:&#39;, data[&#39;r_date&#39;])
    data[&#39;gtid&#39;] = None
    data[&#39;data&#39;] = str(data[&#39;data&#39;])
    if &#39;position&#39; not in data: data[&#39;position&#39;] = &#39;&#39;
    if &#39;server_id&#39; not in data: data[&#39;server_id&#39;] = 0
    if &#39;thread_id&#39; not in data: data[&#39;thread_id&#39;] = 0
    if data[&#39;type&#39;] == &#39;update&#39;:
        data[&#39;old&#39;] = str(data[&#39;old&#39;])
    else:
        data[&#39;old&#39;] = &#39;&#39;
    return data


if __name__ == &quot;__main__&quot;:
    # logging.basicConfig(filename=&#39;example.log&#39;, level=logging.DEBUG)
    logging.basicConfig(level=logging.DEBUG, format=&#39;%(asctime)s - %(name)s - %(levelname)s - %(message)s&#39;)

    ch_setting = {
        &#39;host&#39;: &#39;10.10.4.103&#39;,
        &#39;port&#39;: 9000,
        &#39;user&#39;: &#39;default&#39;,
        &#39;password&#39;: &#39;&#39;,
    }

    chw = ChWriter(ch_setting)
    sql = &quot;INSERT INTO `data_record`.`row_record`(r_date,database,table,type,ts,xid,position,gtid,server_id,thread_id,data,old) VALUES&quot;

    c = Consumer({&#39;bootstrap.servers&#39;: &#39;10.10.4.103:9093&#39;, &#39;group.id&#39;: &#39;0&#39;,
                  &#39;default.topic.config&#39;: {&#39;auto.offset.reset&#39;: &#39;smallest&#39;}})
    c.subscribe([&#39;maxwell&#39;])
    running = True
    while running:
        msg = c.poll()
        if not msg.error():
            r_data = msg.value().decode(&#39;utf-8&#39;)
            print(&#39;Received message: %s&#39; % r_data)
            data = json.loads(r_data)
            prefunc(data)
            chw.ch_insert(sql, [data])
        elif msg.error().code() != KafkaError._PARTITION_EOF:
            print(msg.error())
            running = False
    c.close()
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[python中的迭代]]></title>
    <link href="http://qwerkael.cn/15934208816740.html"/>
    <updated>2020-06-29T16:54:41+08:00</updated>
    <id>http://qwerkael.cn/15934208816740.html</id>
    <content type="html"><![CDATA[
<p>在<code>python</code>中，迭代是一个很重要的概念，当我们使用各种循环的时候，我们就会用到这个概念，比如：<code>for循环</code>。</p>

<p>而<code>for</code>是如何工作的？自己如何在类中实现迭代？下面我们就来了解一下：</p>

<p>首先，我们要了解几个概念：<code>迭代</code>、<code>可迭代对象</code>、<code>迭代器</code>。</p>

<p><code>迭代</code>是一种惰性获取数据的方式，每次返回一个值。</p>

<p><code>可迭代对象</code>，按照字面意思就是可迭代的对象，在<code>Python</code>中，一个可迭代对象都可以通过内置函数<code>iter()</code>返回一个迭代器。而<code>iter()</code>函数则会检查对象中有没有实现<code>__iter__()</code>函数，如果有则调用<code>__iter__()</code>返回一个可迭代对象，如果没有，则检查是否实现了<code>__getitem__()</code>函数，如果有则根据__getitem__()函数生成一个迭代器，按顺序获取元素，如果都没有，则抛出异常，表明对象不可迭代。</p>

<p><code>迭代器</code>实现了<code>__next__()</code>函数，可以返回下一个元素，如果没有下一个元素则返回<code>StopIteration</code>的异常。</p>

<p>而我们在提起迭代器的时候，通常还会提起另一个概念<code>生成器</code>。</p>

<p><code>生成器</code>是一种特殊的迭代器，它能够更优雅的实现迭代器的功能。生成器的特征是使用yield关键字，而不使用<code>__iter__()</code>和<code>__next__()</code>内置函数。</p>

<pre><code class="language-python"># 返回从0开始整数的累加值，大于100结束
# 迭代器
class myIter():
    def __init__(self):
        self.count = 0
        self.sum = 0

    def __iter__(self):
        return self

    def __next__(self):
        self.sum += self.count
        self.count += 1
        return self.sum


if __name__ == &quot;__main__&quot;:
    a = myIter()
    for i in a:
        print(i)
        if i &gt; 100:
            break
</code></pre>

<pre><code class="language-python"># 返回从0开始整数的累加值，大于100结束
# 生成器
def myGen():
    count, sum = 0, 0
    while True:
        yield sum
        count += 1
        sum += count


if __name__ == &quot;__main__&quot;:
    a = myGen()
    for i in a:
        print(i)
        if i &gt; 100:
            break
</code></pre>

<p>我们可以看到使用<code>生成器</code>实现的代码看起来更简介，更pythonic。</p>

<p>使用<code>迭代器</code>时我们需要先创建一个类，然后在类里实现<code>__iter__()</code>和<code>__next__()</code>两个内置函数。</p>

<p>而使用<code>生成器</code>时，我们只需要定义一个函数，在函数中使用<code>yield</code>做返回，也不需要<code>return</code>。</p>

<p>同样的还有<code>生成器表达式</code>，它看起来像一个<code>列表表达式</code>，但是它使用的是<code>()</code>而不是<code>[]</code>，并且它返回的是一个<code>生成器对象</code>，而不是<code>列表</code>。</p>

<pre><code class="language-python"># 列表表达式
[x+1 for x in range(10)]
# 生成器表达式
(x+1 for x in range(10))
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[解决ProxySQL连接MySQL产生大量TIME_WAIT连接的问题]]></title>
    <link href="http://qwerkael.cn/15934213696180.html"/>
    <updated>2020-06-29T17:02:49+08:00</updated>
    <id>http://qwerkael.cn/15934213696180.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>有时候解决一个问题很简单，但是其中发现问题和深入问题的过程却值得我们反复思考</p>
</blockquote>

<h2 id="toc_0">出现了问题</h2>

<p>最近在测试环境新搭的一套<code>proxysql</code>忽然无法正常登录了，一直提示连接<code>hostgroup</code>超时。</p>

<p>我首先跳过<code>proxysql</code>，直接连接后端的<code>mysql</code>节点，确认是<code>proxysql</code>的问题还是<code>mysql</code>的问题。</p>

<p>但是连接一直处于进行中的状态，不提示登录成功也不提示登录失败。</p>

<h2 id="toc_1">初步判断和尝试解决</h2>

<p>初步判断应该是<code>mysql</code>的连接数被打满了。</p>

<p>使用命令查看连接数</p>

<pre><code class="language-shell">netstat -naplt|grep 6033|wc -l
</code></pre>

<p>连接数显示<code>mysql</code>的连接已经被占满了。</p>

<p>由于后端的<code>mysql</code>节点只通过<code>proxysql</code>来访问，其他的程序并不知道<code>mysql</code>实例的端口号，所以尝试重启<code>proxysql</code>来释放连接。</p>

<p>再次尝试连接后端<code>mysql</code>节点，这次直接提示连接数过多，连接失败。</p>

<p>显然，重启<code>proxysql</code>并没有成功的解决问题。</p>

<h2 id="toc_2">挖掘问题并再次尝试解决</h2>

<p>仔细查看<code>netstat</code>输出的信息。</p>

<p>发现绝大部分的连接都是<code>TIME_WAIT</code>。</p>

<p>之后，通过重启<code>mysql</code>暂时的清理掉了这些连接，但是，首先，重启<code>mysql</code>的成本过高，在线上根本不可行，其次，暂时清理掉<code>TIME_WAIT</code>的连接之后，<code>TIME_WAIT</code>的连接数又很快的涨了上来。这并没有从根本上解决问题。</p>

<p>尝试通过<code>proxysql</code>的参数进行连接数限制，但是，<code>TIME_WAIT</code>状态的连接根本不被计算在<code>proxysql</code>的连接中，无法被限制。</p>

<p>查阅资料暂时解决了问题<br/>
查询了相关资料后，发现可以通过修改<code>Linux</code>内核参数来优化<code>TCP连接</code>。</p>

<p>编辑<code>/etc/sysctl.conf</code></p>

<pre><code class="language-ini"># 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；
net.ipv4.tcp_tw_reuse = 1 
# 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。
net.ipv4.tcp_tw_recycle = 1 
# 表示如果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2状态的时间。
net.ipv4.tcp_fin_timeout = 30 
# 表示系统同时保持TIME_WAIT套接字的最大数量，如果超过这个数字，TIME_WAIT套接字将立刻被清除并打印警告信息。
net.ipv4.tcp_max_tw_buckets = 400
</code></pre>

<p>通过开启<code>tcp复用</code>，<code>tcp快速回收</code>，修改<code>tcp fin超时时间</code>依然无法降低<code>TIME_WAIT</code>连接的数量。</p>

<p>最后，通过修改<code>TIME_WAIT</code>的最大保持数量，将<code>TIME_WAIT</code>的连接数量控制在<code>mysql</code>的最大连接数以内，暂时保证了<code>mysql</code>的可用性。</p>

<p>但是，我们依然并没有从根本解决问题。</p>

<h2 id="toc_3">深入了解TIME_WAIT连接尝试解决问题</h2>

<p>为了解决问题，我们先了解一下<code>TIME_WAIT</code>是什么。</p>

<p><img src="media/15934213696180/15934216027787.jpg" alt="tcp_conn"/></p>

<p>在关闭<code>TCP</code>连接的四次握手中，<code>客户端</code>先向<code>服务器端</code>发送<code>FIN报文</code>，告诉服务器端“我要断开连接了”，服务器端收到<code>FIN</code>后会回复一个<code>ACK</code>，表示收到断开连接的请求，但此时<code>服务器端</code>可能仍有数据未发送完，当服务器将数据发送完成后，<code>服务器端</code>会发送一个<code>FIN报文</code>，表示可以断开连接，<code>客户端</code>接收到<code>FIN报文</code>以后会发送一个<code>ACK报文</code>，此时<code>客户端</code>会发送一个<code>ACK报文</code>，然后<code>客户端</code>进入<code>TIME_WAIT</code>状态，当等待<code>2MSL（两个最大报文段生存时间）</code>之后，如果没有再接收到<code>服务器端</code>的请求，连接就会自动断开。</p>

<p>换句话说，当连接进入<code>TIME_WAIT</code>状态以后，我们不需要做任何事情，也无法做任何事情，我们所能做的唯一的事情就是等待一段时间以后，<code>TIME_WAIT</code>的连接就会自动断开。</p>

<p>所以<code>TIME_WAIT</code>的问题并不是连接没有被释放，而是这些<code>TIME_WAIT</code>的连接被创建的太多了。</p>

<p>由于在该环境中，<code>mysql</code>只有<code>proxysql</code>在连接，所以我尝试修改了一些<code>proxysql</code>中关于连接的参数<code>mysql-free_connections_pct</code>、<code>mysql-max_stmts_per_connection</code>等，但是依然无效。</p>

<h2 id="toc_4">问题解决和总结</h2>

<p>最后，该问题的解决是通过修复<code>mysql</code>中<code>monitor</code>用户而解决的。</p>

<p><code>monitor</code>用户是<code>proxysql</code>用以监控<code>mysql</code>的用户，<code>proxysql</code>会定时调用该用户从<code>mysql</code>中获取数据。而在<code>mysql</code>中该用户其实并没有被正确的创建，虽然在一开始我就从<code>log</code>中发现了这个问题，但是我并不认为这会导致<code>mysql</code>节点不可用，所以就忽略了这问题。但是，没有想到，虽然<code>monitor</code>用户无法正常的连接到<code>mysql</code>，但是会创建一个<code>TIME_WAIT</code>的连接。而且，由于不同的尝试连接，导致连接数过大，造成<code>mysql</code>无法使用。</p>

<p>在解决了问题之后，又通过简单的<code>python</code>程序验证了这一状况。</p>

<pre><code class="language-python">import mysql.connector

for i in range(100):
    try:
        conn1 = mysql.connector.connect(user=&#39;aaa&#39;, password=&#39;aaa&#39;, host=&#39;192.168.100.10&#39;, port=3306)
    except (mysql.connector.errors.ProgrammingError) as e:
        print(i + 1, &quot; : &quot;, e)
print(&quot;the end&quot;)
</code></pre>

<p>在上面的脚本中，使用错误的用户名密码不断地连接数据库。</p>

<p>然后，通过监控<code>TIME_WAIT</code>数量，发现虽然连接都失败了，但是每一次尝试连接都会产生一个<code>TIME_WAIT</code>的连接。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[yaourt/pacman加速3连]]></title>
    <link href="http://qwerkael.cn/15934218730531.html"/>
    <updated>2020-06-29T17:11:13+08:00</updated>
    <id>http://qwerkael.cn/15934218730531.html</id>
    <content type="html"><![CDATA[
<p>这两天更新包的时候感觉速度有点慢，于是就做了一些优化改进，顺手总结一下</p>

<ol>
<li><p>改源<br/>
将下载源改成国内源是最常见的一种，不过<code>Arch</code>一般在安装的时候就会进行改源操作。</p>
<p>在<code>/etc/pacman.d/mirrorlist</code>中包含的源已经很全了，我们只需要将不需要的一些国外源注释掉或者删掉就行了。</p>
<p>另外，我们一般也会添加一下<code>archlinuxcn</code>的镜像源。</p>
<p>只需要修改一下<code>/etc/pacman.conf文件</code>，在最底下添加</p>
<pre><code class="language-ini">[archlinuxcn]
Server = https://mirrors.ustc.edu.cn/archlinuxcn/$arch
</code></pre>
<p>然后安装一下<code>archlinuxcn-keyring</code></p>
<pre><code class="language-shell">yaourt -S archlinuxcn-keyring
</code></pre></li>
<li><p>并行<br/>
<code>pacman</code>默认是使用<code>wget</code>进行下载的，我们可以在配置中，将它改为其他的多线程下载工具</p>
<p>编辑配置文件<code>/etc/pacman.conf</code>，添加以下参数</p>
<pre><code class="language-shell">XferCommand = /usr/bin/aria2c -s 5 %u
</code></pre>
<p>可以调节<code>-s</code>后面的参数，修改并行数</p></li>
<li><p>加代理<br/>
有时候我们下载国外网站的一些包的时候可能需要科学上网，下面提供一种方法可以让命令行通过ss进行科学上网</p>
<pre><code class="language-shell"># 安装privoxy
sudo pacman -S privoxy<br/>
# 编辑配置文件<br/>
sudo vim /etc/privoxy/config<br/>
# 在文件中添加一行（最后有一个点，别漏了）<br/>
forward-socks5 / 127.0.0.1:7070 .<br/>
# 启动privoxy服务<br/>
sudo systemctl start privoxy.service<br/>
# 配置环境变量<br/>
export https_proxy=127.0.0.1:8118<br/>
export http_proxy=127.0.0.1:8118
</code></pre></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[安装合集]]></title>
    <link href="http://qwerkael.cn/15934220934752.html"/>
    <updated>2020-06-29T17:14:53+08:00</updated>
    <id>http://qwerkael.cn/15934220934752.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>汇总了一些常见软件的安装命令，复制即用，炒鸡简单【CentOS】</p>
</blockquote>

<h2 id="toc_0">EPEL【yum】</h2>

<p><code>epel</code>几乎是<code>CentOS</code>的必备很多软件和依赖都可以在<code>epel</code>中找到</p>

<pre><code class="language-shell">yum install epel-release
</code></pre>

<h2 id="toc_1">MySQL【yum】</h2>

<pre><code class="language-shell"># 安装 Percona 仓库
yum install http://www.percona.com/downloads/percona-release/redhat/0.1-4/percona-release-0.1-4.noarch.rpm 
# mysql5.7 
yum install Percona-Server-client-57 Percona-Server-devel-57 Percona-Server-server-57 Percona-Server-shared-57 
# mysql5.6 
yum install Percona-Server-client-56 Percona-Server-devel-56 Percona-Server-server-56 Percona-Server-shared-56 
# 相关的软件和工具 
yum install percona-xtrabackup-24 percona-toolkit 
# mysql5.7的一些准备工作
# mysql5.7初始化
$ mysqld --initialize
# mysql5.7中使用了一些新的密码策略，所以我们的配置会麻烦一些
# mysql5.7中，root用户是有初始密码的，改密码存在mysql的错误日志中
$ grep &quot;password&quot; /var/log/mysqld.log
2017-06-17T12:25:17.375581Z 1 [Note] A temporary password is generated for root@localhost: cul+b=F7vF*o
# mysql5.7中会检查密码的复杂度，简单的密码无法被设置，我们可以关闭该策略，在生产环境中不建议这么做
set global validate_password_policy=0;
# 虽然我们可以设置简单的密码了，但是mysql对于密码的长度还是有要求的，该值也可以被修改，同步不建议在生产环境这么做
set global validate_password_length=1;
# 然后我们就可以修改root用户的密码了
ALTER USER USER() IDENTIFIED BY &#39;123456&#39;;
</code></pre>

<h2 id="toc_2">Redis【yum】</h2>

<pre><code class="language-shell"># Redis在epel中就有，不过版本一般比较老，要安装新版的redis可以在remi源中找
# 安装 remi 源
# CentOS6版本的remi源
yum install https://mirrors.tuna.tsinghua.edu.cn/remi/enterprise/remi-release-6.rpm 
# CentOS7版本的remi源
yum install https://mirrors.tuna.tsinghua.edu.cn/remi/enterprise/remi-release-7.rpm 
# 启用remi，并查看可以安装的redis版本
yum --enablerepo=remi list redis --showduplicates
# 选择合适的版本安装就可以了，软件名和版本号之间用“-”链接
</code></pre>

<h2 id="toc_3">NodeJS【yum】</h2>

<pre><code class="language-shell"># 安装9.x的仓库
curl -sL https://rpm.nodesource.com/setup_9.x | bash -
# 安装8.x的仓库
curl -sL https://rpm.nodesource.com/setup_8.x | bash -
# 安装nodejs
yum install -y nodejs
# 安装cnpm
npm install -g cnpm --registry=https://registry.npm.taobao.org
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用Navicat链接proxysql无法进行用户管理]]></title>
    <link href="http://qwerkael.cn/15934225595265.html"/>
    <updated>2020-06-29T17:22:39+08:00</updated>
    <id>http://qwerkael.cn/15934225595265.html</id>
    <content type="html"><![CDATA[
<p>今天使用<code>Navicat</code>链接<code>proxysql</code>修改后端数据库用户权限的时候，莫名其妙的出现了一个报警<br/>
<img src="media/15934225595265/15934225922074.jpg" alt=""/><br/>
这个问题在之前并没有遇到过，看这个描述，因该是找不到<code>password</code>字段，初步的猜测是在<code>proxysql</code>中设置的<code>mysql</code>版本号和实际连接的<code>mysql</code>版本号不一致，而恰巧这两个版本中记录<code>mysql</code>用户信息的表结构也不一致，导致<code>Navicat</code>根据错误的版本号使用了错误的查询语句，最后导致查询报错。</p>

<p>随后我查询的<code>proxysql</code>中标记的版本号，和后端连接的<code>mysql</code>的版本号，发现这两个值确实不一致，而直接连接后端的数据库访问用户管理项的时候，也没有报错。</p>

<p>那么事情就好办了，修改一下<code>proxysql的mysql-server_version</code>然后<code>load mysql variables to run;</code>，完结，撒花～</p>

<p>…</p>

<p>…</p>

<p>但是事情永远不可能向你想象中的那么顺利，<code>load</code>之后，报错依旧。</p>

<p>这。。。</p>

<p>好，祭出牛刀，<code>tcpflow</code></p>

<p><code>tcpflow</code>和<code>tcpdump</code>差不多，都是抓包的，但是个人感觉比<code>tcpdump</code>好用</p>

<p>怎么安装就不说了，我本地是<code>ArchLinux</code>，直接<code>yaourt</code>就可以了，<code>CentOS</code>的我以后可能会写篇文章单独讲。</p>

<p>直接上命令，查看发往<code>proxysql</code>的流量</p>

<pre><code class="language-shell">$ sudo tcpflow -c -p -i any dst port 3306
</code></pre>

<p>于是可以看到，当我们在<code>Navicat</code>上点击用户表单的时候，会向<code>mysql</code>发送一条命令</p>

<pre><code class="language-shell">SELECT user, host, password, ssl_type, ssl_cipher, x509_issuer, x509_subject, max_questions, max_updates, max_connections, super_priv, max_user_connections FROM mysql.user ORDER BY user
</code></pre>

<p>这里会查询一个<code>password</code>字段，而当我们直接连接后端的<code>mysql</code>节点的时候，发送的请求是</p>

<pre><code class="language-shell">SELECT user, host, authentication_string, ssl_type, ssl_cipher, x509_issuer, x509_subject, max_questions, max_updates, max_connections, super_priv, max_user_connections, plugin, password_expired, password_lifetime FROM mysql.user ORDER BY user
</code></pre>

<p>注意，这里已经没有了<code>password</code>字段，取而代之的是<code>authentication_string</code>字段，这就是<code>5.6</code>版本和<code>5.7</code>版本的区别。</p>

<p>但是我明明已经将<code>proxysql</code>中的版本号改掉，并且<code>load</code>了，但是为什么没有生效？！</p>

<p>好吧，可能是bug吧，事实上<code>proxysql</code>虽然号称可以试试修改配置项，但是实际操作中配置项修改后不能实时生效的绝对不知这一处，比如修改监听端口就需要重启服务才能生效。</p>

<p>那么我们保存配置<code>save mysql variables to disk;</code></p>

<p>然后重启服务</p>

<pre><code class="language-shell">$ service proxysql restart
</code></pre>

<p>再次用Navicat访问用户表单，终于正常了。</p>

<p>整个总结下来就两个字<code>坑爹</code></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用cachecloud和codis搭建redis环境]]></title>
    <link href="http://qwerkael.cn/15934230143658.html"/>
    <updated>2020-06-29T17:30:14+08:00</updated>
    <id>http://qwerkael.cn/15934230143658.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">简单的介绍：</h2>

<p>CacheCloud：<br/>
<code>CacheCloud</code>是由<code>souhutv</code>开源一套<code>Redis</code>的管理系统，可以帮助我们自动化的搭建和运维<code>Redis</code>，<code>Cachecloud</code>可以自动部署和管理3种形式的Redis方案，包括单实例<code>Redis</code>，<code>Redis+Sentinel</code>以及Redis的原生集群方案<code>Redis Cluster</code></p>

<p>Codis：<br/>
<code>Codis</code>是由豌豆荚开源的一套Redis集群方案，是通过proxy路由到不同分片来实现的<code>redis</code>集群</p>

<h2 id="toc_1">Codis安装：</h2>

<h3 id="toc_2">1. 安装Go环境</h3>

<pre><code class="language-text">在Go语言的下载页面选择一个你要使用的安装包下载。我选择的是1.9.2版本。
```shell
wget https://redirector.gvt1.com/edgedl/go/go1.9.2.linux-amd64.tar.gz
```
修改/etc/profile文件
```shell
export GOROOT=/data/go/
export PATH=$PATH:/$GOROOT/bin
```
重新加载/etc/profile
```shell
source /etc/profile
```
查看Go是否安装成功
```shell
$ go version
go version go1.9.2 linux/amd64
```
</code></pre>

<h3 id="toc_3">2. 安装Codis</h3>

<pre><code class="language-text">首先我们需要知道`GOPATH`的路径
```shell
$ go env GOPATH
/root/go
```
Go安装成功后，GOPATH会在`～/go`目录下，我这值我们也可以进行修改，比如，修改为`/data/gopath`
```shell
export GOPATH=/data/gopath
```
然后我们需要将codis的代码`clone`到指定的目录下
```shell
$ mkdir -p $GOPATH/src/github.com/CodisLabs
$ cd $GOPATH/src/github.com/CodisLabs
$ git clone https://github.com/CodisLabs/codis.git -b release3.2
```
获取到源码后，我们只需要`make`一下就可以了
```shell
$ cd codis
$ make
make -j4 -C extern/redis-3.2.11/
make[1]: 进入目录“/data/gopath/src/github.com/CodisLabs/codis/extern/redis-3.2.11”
cd src &amp;&amp; make all
...
```
在这个过程中你可能需要安装一些工具，比如
```shell
yum groupinstall &quot;Development Tools&quot;
```
在安装过程中可能会遇到如下的错误

&gt; zmalloc.h:50:31: 致命错误：jemalloc/jemalloc.h：没有那个文件或目录

这是因为没有找到`jemalloc`内存管理器的缘故，
我们可以在编译的时候指定其他的内存管理
```shell
make MALLOC=libc
```
但是相比`jemalloc`，其他的内存管理器可能会造成更多的内存碎片（`mem_fragmentation_ratio`）
当然，为了更好的性能，我们自然会选择`jemalloc`，那么我们就需要安装`jemalloc`了，但是如果我们现在使用`yum`安装，可以依然会编译`codis`报错，因为`jemalloc`没有被安装到指定的目录，而在`redis`的安装包里`redis`自己就为我们提供一个`deps`目录，里面就有`jemalloc`和其他一些依赖的安装包。
但是`codis`的目录下为我们提供了多个版本的`redis`，我们需要使用那个呢？
刚才我们在`make`的时候，第一行输出是
```shell
make -j4 -C extern/redis-3.2.11/
```
这里我们就可以进入该目录，直接编译deps下的所有依赖
```shell
cd extern/redis-3.2.11/deps
make hiredis jemalloc linenoise lua geohash-int
```
再次回到原目录，编译成功
</code></pre>

<h2 id="toc_4">启动Codis：</h2>

<h3 id="toc_5">启动<code>Codis</code>会用到<code>zk</code>或者<code>etctd</code>，这里我使用的是<code>zk</code></h3>

<p>安装<code>JDK</code>和<code>ZOOKEEPER</code>`<code><br/>
</code>JDK<code>可以直接使用</code>yum`安装</p>

<pre><code class="language-shell">yum install java-1.8.0-openjdk java-1.8.0-openjdk-devel
</code></pre>

<p>安装完<code>JDK</code>记得要配置环境变量，不然可能会导致一些程序不可用<br/>
<code>vim /etc/profile</code></p>

<pre><code class="language-shell">#set java environment  
JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.151-1.b12.el6_9.x86_64
PATH=$PATH:$JAVA_HOME/bin
CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
export JAVA_HOME  CLASSPATH  PATH
</code></pre>

<p>加载一下配置文件<code>source /etc/profile</code></p>

<p>ZOOKEEPER需要从官网下载安装包，我部署的是单节点的，解压后直接启动就可以</p>

<pre><code class="language-shell">wget http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.11/zookeeper-3.4.11.tar.gz
tar -zxf zookeeper-3.4.11.tar.gz
cd zookeeper-3.4.11/conf
cp zoo_sample.cfg zoo.cfg
cd zookeeper-3.4.11/bin
./zkServer.sh start
</code></pre>

<h3 id="toc_6">配置与启动</h3>

<p><img src="media/15934230143658/15934236957711.jpg" alt="codis架构图"/></p>

<p>如上图，Codis集群架构可以分为几个部分</p>

<p>最核心的是<code>codis-dashboard</code>和<code>codis-proxy</code></p>

<ul>
<li><code>codis-dashboard</code>是<code>codis</code>的集群管理工具，可以管理<code>codis-proxy</code>、<code>codis-server</code>和<code>Redis-sentinel</code></li>
<li><code>codis-proxy</code>负责<code>codis</code>集群中的代理工作，负责将<code>redis</code>命令路由到不同的分片</li>
<li><code>codis-fe</code>是<code>codis-dashboard</code>的<code>web</code>管理界面，可以更方便、更形象的管理集群</li>
<li><code>codis-serer</code>是在<code>redis-server</code>基础上增加了<code>codis</code>相关命令而形成的另一个分支
现在我们要启动<code>Codis</code></li>
</ul>

<p>我们先进入<code>codis</code>的配置文件目录<code>/data/gopath/src/github.com/CodisLabs/codis/config</code>修改<code>codis-dashboard</code>的配置文件，<code>codis-dashboard</code>默认使用<code>filesystem</code>作为外部存储，我们将其修改为<code>zookeeper</code>。</p>

<p>然后将<code>product_name</code>修改为该我们的<code>codis</code>集群的名字，这里我们改成<code>codis-test</code></p>

<pre><code class="language-shell"># Set Coordinator, only accept &quot;zookeeper&quot; &amp; &quot;etcd&quot; &amp; &quot;filesystem&quot;.
# for zookeeper/etcd, coorinator_auth accept &quot;user:password&quot; 
# Quick Start
# coordinator_name = &quot;filesystem&quot;
# coordinator_addr = &quot;/tmp/codis&quot;
coordinator_name = &quot;zookeeper&quot;
coordinator_addr = &quot;127.0.0.1:2181&quot;
#coordinator_auth = &quot;&quot;

# Set Codis Product Name/Auth.
product_name = &quot;codis-test&quot;
product_auth = &quot;&quot;
</code></pre>

<p>现在启动<code>codis-dashboard</code></p>

<pre><code class="language-shell">nohup ./bin/codis-dashboard --ncpu=4 --config=config/dashboard.toml --log=logs/dashboard.log --log-level=WARN &amp;
</code></pre>

<p>这里我新建了一个<code>logs</code>目录来存放日志</p>

<p><code>codis-proxy</code>也有相应的配置文件，这里我只是简单的修改了一下<code>product_name</code>，然后启动相关的服务</p>

<pre><code class="language-shell"># 启动 codis-proxy
nohup ./bin/codis-proxy --ncpu=4 --config=config/proxy.toml --log=logs/proxy.log --log-level=WARN &amp;
# 启动 codis-fe，这里监听的是8080端口
nohup ./bin/codis-fe --ncpu=4 --log=logs/fe.log --log-level=WARN --zookeeper=127.0.0.1:2181 --listen=0.0.0.0:8080 &amp;
</code></pre>

<p>现在我们已经可以访问管理页面了</p>

<p>进入管理界面中，我们先添加一个<code>proxy</code></p>

<p><img src="media/15934230143658/15934240026925.jpg" alt="添加codis-proxy"/></p>

<p>接下来我们就可以添加<code>codis-server</code>和<code>sentinel</code>了，但是在那之前，我们先安装一下<code>CacheCloud</code></p>

<h2 id="toc_7">安装CacheCloud：</h2>

<p>我们先从<del>gayhub</del> github上 的获取源码</p>

<pre><code class="language-shell">cd /opt
git clone https://github.com/sohutv/cachecloud.git
</code></pre>

<p>由于程序需要用到<code>maven</code>，我们需要先安装<code>maven</code></p>

<pre><code class="language-shell">wget http://repos.fedorapeople.org/repos/dchen/apache-maven/epel-apache-maven.repo -O /etc/yum.repos.d/epel-apache-maven.repo
yum -y install apache-maven
</code></pre>

<p>现在我们需要修改一下配置文件，配置一下使用的<code>mysql</code>和监听的端口</p>

<pre><code class="language-shell">$ vim /opt/cachecloud/cachecloud-open-web/src/main/swap/online.properties
cachecloud.db.url = jdbc:mysql://127.0.0.1:3306/cache-cloud
cachecloud.db.user = admin
cachecloud.db.password = 123456
cachecloud.maxPoolSize = 20

isClustered = true
isDebug = false
spring-file=classpath:spring/spring-online.xml
log_base=/opt/cachecloud-web/logs
web.port=8585
log.level=WARN
</code></pre>

<p>启动<code>cachecloud</code></p>

<pre><code class="language-shell"># 进入cachecloud的根目录
cd /opt/cachecloud
# 运行maven
mvn clean compile install -Ponline
# 新建cachecloud-web目录
mkdir /opt/cachecloud-web
# 拷贝war包、配置文件和启动脚本
cp /opt/cachecloud/cachecloud-open-web/target/cachecloud-open-web-1.0-SNAPSHOT.war /opt/cachecloud-web
cp /opt/cachecloud/cachecloud-open-web/src/main/resources/cachecloud-web.conf /opt/cachecloud-web
cp /opt/cachecloud/script/st*.sh /opt/cachecloud-web
# 初始化数据库
mysql -uadmin -p -D&#39;cache-cloud&#39; &lt; /opt/cachecloud/script/cachecloud.sql
# 启动
sh /opt/cachecloud-web/start.sh
</code></pre>

<p>如果你发现启动脚本运行的时间很长，可能是已经报错了，<code>tail</code>一下日志</p>

<p>如果报<code>Unrecognized VM option &#39;UnlockCommercialFeatures&#39;</code>的错误，在启动脚本中将<code>-XX:+UnlockCommercialFeatures -XX:+FlightRecorder</code>去掉即可</p>

<h2 id="toc_8">使用CacheCloud和配置Redis：</h2>

<p>在<code>cachecloud</code>的<code>script</code>目录下有一个初始化脚本<code>cachecloud-init.sh</code></p>

<p>这个脚本有3个作用：</p>

<ol>
<li>创建cachecloud项目的用户</li>
<li>创建cachecloud项目的相关目录</li>
<li>安装redis</li>
</ol>

<p>将这个脚本拷贝到需要管理的机器上，然后执行</p>

<pre><code class="language-shell">./cachecloud-init.sh username
</code></pre>

<p>此处的<code>username</code>是你用于创建管理<code>redis</code>的用户名</p>

<p>执行后，你需要输入两次密码</p>

<p>使用管理员账号进入<code>web</code>管理页面，在<code>管理后台</code>&gt;<code>机器管理</code>中添加我们初始化后的机器</p>

<p>接着，我们可以使用任意账号在应用申请界面申请<code>redis</code>服务</p>

<p><code>cachecloud</code>提供3种<code>redis</code>服务</p>

<ol>
<li>单节点redis</li>
<li>Redis-Sentinel</li>
<li>原生的Redis-Cluster集群</li>
</ol>

<p>申请了我们需要的<code>redis</code>服务之后，管理员就可以在<code>管理后台</code>&gt;<code>流程审批</code>界面分配<code>redis</code>服务了</p>

<h2 id="toc_9">使用CacheCloud配置Codis集群</h2>

<h3 id="toc_10">为codis添加redis-server</h3>

<p>值得注意的是，<code>Codis</code>集群不能直接使用<code>Redis-Server</code>，我们需要使用<code>codis</code>安装目录下的<code>codis-server</code>替换掉<code>PATH</code>路径下的<code>redis-server</code></p>

<pre><code class="language-shell">cp codis-server /usr/bin/redis-server
cp codis-server /usr/local/bin/redis-server
</code></pre>

<p>这样我们使用<code>CacheCloud</code>创建的就是<code>codis-server</code>了</p>

<p>现在我们在<code>CacheCloud</code>中创建两个单节点<code>redis</code>，然后在<code>管理后台</code>&gt;<code>流程审批</code>&gt;<code>应用运维</code>中为两个<code>redis</code>分别配置<code>slave</code></p>

<p>现在我们得到了两对<code>redis</code>主从，然后我们进入<code>Codis</code>的管理界面，在<code>Group</code>中将这两对主从添加为两组<code>Group</code>，再在<code>Slots</code>中点击<code>Reblance All Slots</code></p>

<p>至此<code>Codis</code>集群就搭建完成了</p>

<p>现在我们为<code>Codis</code>集群添加<code>Sentinel</code></p>

<h3 id="toc_11">为什么要手动启动<code>sentinel</code></h3>

<p>需要说明的一点是，我们可以在<code>CacheCloud</code>中可以直接配置<code>Redis-Sentinel</code>集群，似乎我们直接在<code>CacheCloud</code>中配置好<code>Redis-Sentinel</code>集群，然后将配置好的<code>redis</code>和<code>sentinel</code>添加到<code>codis</code>中，这样更简单。但是这样做是不可行的。</p>

<p>正常情况下，添加了<code>sentinel</code>的<code>codis</code>集群在<code>redis-server</code>主节点宕机后，<code>codis-proxy</code>会自动<code>failover</code>到<code>redis-server</code>从节点。</p>

<p>但是，但是如果<code>codis</code>添加的是通过<code>cachecloud</code>生成的<code>sentinel</code>，则由于<code>cachecloud</code>和<code>codis</code>都对<code>sentinel</code>进行了配置，导致<code>sentinel</code>对同一套主从侦测了两次，在<code>redis-server</code>主节点宕机后，<code>sentinel</code>的<code>cachecloud</code>配置生效，而<code>codis</code>配置不生效，所以<code>codis-proxy</code>无法正常<code>failover</code>。</p>

<p>所以在<code>cachecloud</code>和<code>codis</code>联合使用时，不要在<code>codis</code>中配置<code>cachecloud</code>生成的<code>sentinel</code>。</p>

<p>而为<code>codis</code>单独配置<code>sentinel</code>也很简单。</p>

<h3 id="toc_12">添加sentinel</h3>

<p>首先创建一个简单的配置文件</p>

<pre><code class="language-shell">$ vim sentinel.conf 
port 26379
dir /tmp
protected-mode no # 较早的redis版本不需要该参数
</code></pre>

<p>然后启动<code>sentinel</code></p>

<pre><code class="language-shell">redis-server sentinel.conf --sentinel &amp;
</code></pre>

<p>然后我们添加<code>sentinel</code>的地址添加到<code>codis</code>配置页面的<code>sentinels</code>配置项中即可。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[tilda 无法设置透明模式]]></title>
    <link href="http://qwerkael.cn/15934280345906.html"/>
    <updated>2020-06-29T18:53:54+08:00</updated>
    <id>http://qwerkael.cn/15934280345906.html</id>
    <content type="html"><![CDATA[
<p>一觉醒来打开电脑，发现日常使用的<code>tilda</code>终端忽然无法显示<code>透明</code>特效了。</p>

<p>重新进入首选项进行配置，但是根本不管用。</p>

<p>google一下，发现<code>github</code>上有相关的<a href="https://github.com/lanoxx/tilda/issues/228"><code>issue</code></a>。</p>

<p>有人说是<code>配置文件</code>的问题。但是我修改配置文件后依然无效。</p>

<p>有人说是<code>系统设置</code>的问题。于是打开<code>系统设置</code>（不同的电脑设置的不一样，我是 <code>Arch</code> + <code>KDE</code>）搜索<code>composit（混合器）</code>，点进去就发现有报错，说是后端渲染OpenGL崩溃了，在该页面重新配置OpenGL，应用配置。</p>

<p><img src="media/15934280345906/15934281297318.jpg" alt="opengl_err"/></p>

<p>然后关闭<code>tilda</code>重新打开，<code>tilda</code>又可以显示透明特效了。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[OpenTSDB 的安装与部署]]></title>
    <link href="http://qwerkael.cn/15934277592153.html"/>
    <updated>2020-06-29T18:49:19+08:00</updated>
    <id>http://qwerkael.cn/15934277592153.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">安装 JDK</h2>

<p>jdk直接使用yum安装，原因嘛～我懒！</p>

<pre><code class="language-shell">yum install java-1.8.0-openjdk java-1.8.0-openjdk-devel
</code></pre>

<p>安装完<code>jdk</code>记得要配置环境变量，不然可能会导致一些程序不可用<br/>
<code>vim /etc/profile</code></p>

<pre><code class="language-shell">#set java environment  
JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.151-1.b12.el6_9.x86_64
PATH=$PATH:$JAVA_HOME/bin
CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
export JAVA_HOME  CLASSPATH  PATH
</code></pre>

<p>加载一下配置文件<code>source /etc/profile</code></p>

<h2 id="toc_1">安装 HBase</h2>

<pre><code class="language-shell"># 创建存放数据的目录
cd /data
mkdir zookeeper hbase
# 下载hbase，我用的是1.4版本的
cd /soft
wget http://mirrors.shuosc.org/apache/hbase/1.4.0/hbase-1.4.0-bin.tar.gz
tar -zxf hbase-1.4.0-bin.tar.gz
cd hbase-1.4.0
</code></pre>

<p>修改配置文件<code>hbase-site.xml</code>，添加<code>hbase</code>的目录和<code>zookeeper</code>的目录</p>

<pre><code class="language-markup">&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;hbase.rootdir&lt;/name&gt;
    &lt;value&gt;file:///data/hbase&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;
    &lt;value&gt;/data/zookeeper&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>修改配置文件<code>hbase-env.sh</code>，取消下面行的注释，让<code>hbase</code>自己管理一个<code>zookeeper</code></p>

<pre><code class="language-shell">export HBASE_MANAGES_ZK=true
</code></pre>

<h2 id="toc_2">启动和关闭<code>HBase</code></h2>

<pre><code class="language-shell">/soft/hbase-1.4.0/bin/start-hbase.sh
/soft/hbase-1.4.0/bin/stop-hbase.sh
</code></pre>

<p>查看<code>hbase</code>时候启动了，可以使用<code>/soft/hbase-1.4.0/bin/hbase shell</code>命令进入<code>hbase</code>的命令行模式，使用<code>version</code>命令查看版本号</p>

<h2 id="toc_3">安装OpenTSDB</h2>

<p>安装依赖的程序，gnuplot，这是一个绘图的程序</p>

<pre><code class="language-shell">yum install gnuplot
</code></pre>

<p>然后去<a href="https://github.com/OpenTSDB/opentsdb/releases">OpenTSDB的GitHub</a>下载最新的<code>rpm包</code>，并安装</p>

<pre><code class="language-shell">yum localinstall opentsdb-2.3.0.rpm
</code></pre>

<p>修改配置文件<code>vim /etc/opentsdb/opentsdb.conf</code></p>

<pre><code class="language-shell"># 监听的配置端口号
tsd.network.port = 4242
# 监听的配置ip
tsd.network.bind = 0.0.0.0
# 自动创建metric，建议开启
tsd.core.auto_create_metrics = true
# 配置使用的zk
tsd.storage.hbase.zk_quorum = localhost:2181
</code></pre>

<p>初始化数据库</p>

<pre><code class="language-shell">env COMPRESSION=NONE HBASE_HOME=/usr/hdp/current/hbase-client/ /usr/share/opentsdb/tools/create_table.sh
</code></pre>

<p>创建日志目录</p>

<pre><code class="language-shell">mkdir -p /data/logs/opentsdb
</code></pre>

<p>启动OpenTSDB</p>

<pre><code class="language-shell">nohup tsdb tsd &gt; /var/log/opentsdb/opentsdb.out &amp;
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[远程访问ProxySQL管理端口]]></title>
    <link href="http://qwerkael.cn/15934266845726.html"/>
    <updated>2020-06-29T18:31:24+08:00</updated>
    <id>http://qwerkael.cn/15934266845726.html</id>
    <content type="html"><![CDATA[
<p>自<code>1.4.1</code>版本以后<code>ProxySQL</code>默认支持远程链接管理端口（<code>admin-mysql_ifaces：“0.0.0.0:6032”</code>），但是不能使用<code>admin</code>用户，<code>admin</code>支持从本地访问。</p>

<p>可以配置参数<code>admin-admin_credential</code>支持多个用户，例如：</p>

<p><code>admin-admin_credentials=&quot;admin:admin;admin2:pass2&quot;</code></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用python链接redis sentinel]]></title>
    <link href="http://qwerkael.cn/15934266055742.html"/>
    <updated>2020-06-29T18:30:05+08:00</updated>
    <id>http://qwerkael.cn/15934266055742.html</id>
    <content type="html"><![CDATA[
<pre><code class="language-python">from redis.sentinel import Sentinel // 导入sentinel包
sentinel = Sentinel([(&#39;10.60.0.16&#39;,6388)],socket_timeout=0.1) // 获取sentinel的链接
sentinel.discover_master(&#39;sentinel-10.60.0.16-6386&#39;) // 获取master地址
sentinel.discover_slaves(&#39;sentinel-10.60.0.16-6386&#39;) // 获取slave地址
master = sentinel.master_for(&#39;sentinel-10.60.0.16-6386&#39;,socket_timeout=0.1) //获取master的连接
slave = sentinel.slave_for(&#39;sentinel-10.60.0.16-6386&#39;,socket_timeout=0.1) // 获取slave的连接
master.set(&#39;name&#39;,&#39;alex&#39;) // 向master插入一个值
slave.get(&#39;name&#39;) // 从slave获取该值
</code></pre>

<p>进入<code>master</code>实例,使用<code>shutdown</code>命令关闭<code>master</code>实例，再次使用<code>master.get(&#39;name&#39;)</code>命令从<code>master</code>实例取值，<code>python</code>报错<code>Connection refused</code>，可见由于<code>master</code>宕机，导致连接断开。</p>

<p>过了几秒后再次执行<code>master.get(&#39;name&#39;)</code>命令，命令正常返回值，<code>sentinel</code>已经进行了<code>failover</code>处理，并且<code>master</code>连接重新连接到了新的<code>master</code>实例</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[解决PHP连接Proxysql出现乱码的问题]]></title>
    <link href="http://qwerkael.cn/15934271804942.html"/>
    <updated>2020-06-29T18:39:40+08:00</updated>
    <id>http://qwerkael.cn/15934271804942.html</id>
    <content type="html"><![CDATA[
<p>PHP使用Laravel框架连接Proxysql有时会出现乱码。</p>

<p>这种问题的出现一般是在PHP初始化连接的时候并没有设置正确的字符集，而在连接建立后使用Prepare Statement的方式设置字符集导致的。</p>

<p>Proxysql本身支持设置字符集（如，SET NAMES utf8mb4），但是对于用<code>Prepare Statement</code>设置字符集的方式支持的并不好，所以会导出出现乱码。</p>

<p>解决该问题可以参考一下两种方法：</p>

<ol>
<li>在vendor/laravel/framework/src/Illuminate/Database/Connectors/Connector.php中添加 PDO::MYSQL_ATTR_INIT_COMMAND =&gt; &#39;SET NAMES utf8mb4&#39;</li>
<li><p>在vendor/laravel/framework/src/Illuminate/Database/Connectors/MySqlConnector.php中将</p>
<pre><code class="language-php">protected function getHostDsn(array $config)
{<br/>
  extract($config);<br/>
  return isset($config[&#39;port&#39;])<br/>
                ? &quot;mysql:host={$host};port={$port};dbname={$database}&quot;<br/>
                : &quot;mysql:host={$host};dbname={$database}&quot;;<br/>
}
</code></pre>
<p>修改为</p>
<pre><code class="language-php">protected function getHostDsn(array $config)
{<br/>
  extract($config);<br/>
  return isset($config[&#39;port&#39;])<br/>
                ? &quot;mysql:host={$host};port={$port};dbname={$database};charset=utf8mb4&quot;<br/>
                : &quot;mysql:host={$host};dbname={$database};charset=utf8mb4&quot;;<br/>
}
</code></pre></li>
</ol>

<p>参考文章：<br/>
<a href="https://github.com/sysown/proxysql/issues/780">https://github.com/sysown/proxysql/issues/780</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用Proxysql进行权限控制]]></title>
    <link href="http://qwerkael.cn/15934265613726.html"/>
    <updated>2020-06-29T18:29:21+08:00</updated>
    <id>http://qwerkael.cn/15934265613726.html</id>
    <content type="html"><![CDATA[
<p>对MySQL进行权限控制可以更好的维护数据库的高可用，也可以更方便的定位问题。</p>

<p>权限控制可以分为两层，一层是向外对IP做控制，一层是向内对库表做控制。</p>

<p>当我们使用Proxysql中间件以后，由于数据库的IP入口只有Proxysql服务了，所以我们只能够通过Proxysql来对外部的服务IP做控制。</p>

<p>而对内的库表权限控制，Proxysql目前还不支持，所以只能通过MySQL原生的权限管理来实现。</p>

<p>P.S.:在Proxysql管理端口下的mysql_users表中，有 backend 和 frontend 字段。Proxysql的官方文档的解释是，Proxysql将会从 backend 和 frontend 两个层面来支持user的权限控制，即从client到proxysql和从proxysql到mysql两个阶段来分别控制user的权限。到时候我们就可以将不同的frontend账户路由到同一个backend账户，或者反之。但是目前该功能还没实现。</p>

<h2 id="toc_0">通过Proxysql对IP访问权限控制：</h2>

<p>Proxysql对IP的控制需要在query rules做控制，通过client_addr字段来控制访问的ip，但是不能进行模糊匹配或者正则匹配。所以要做IP控制只能一个IP一个IP的添加。</p>

<h2 id="toc_1">通过Proxysql和iptables对IP访问权限控制：</h2>

<p>由于proxysql不能进行批量匹配ip地址，所以我们可以iptables进行ip地址匹配，但是这样我们就无法对服务地址和服务使用的mysql账户关联起来进行限制了。</p>

<p>为此，我们可以使用mysql-interfaces参数让proxysql监听多个端口，为每一个服务分配一个端口，在query rules里通过proxy_addr和proxy_port参数来根据proxysql的端口进行路由规则的配置。</p>

<h2 id="toc_2">通过MySQL对库表进行权限管理：</h2>

<p>MySQL的授权语句可以对库级别和表级别进行不同权限的细化的权限管理。</p>

<p>需要注意的是服务器使用的用户需要在Proxysql和MySQL同时进行注册才能够正常的使用。</p>

]]></content>
  </entry>
  
</feed>
